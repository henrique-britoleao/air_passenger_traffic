{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a href=\"http://www.datascience-paris-saclay.fr\">Paris Saclay Center for Data Science</a>\n",
    "# <a href=https://www.ramp.studio/problems/air_passengers>RAMP</a> on predicting the number of air passengers\n",
    "\n",
    "<i> Balázs Kégl (LAL/CNRS), Alex Gramfort (Inria), Djalel Benbouzid (UPMC), Mehdi Cherti (LAL/CNRS) </i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "The data set was donated to us by an unnamed company handling flight ticket reservations. The data is thin, it contains\n",
    "<ul>\n",
    "<li> the date of departure\n",
    "<li> the departure airport\n",
    "<li> the arrival airport\n",
    "<li> the mean and standard deviation of the number of weeks of the reservations made before the departure date\n",
    "<li> a field called <code>log_PAX</code> which is related to the number of passengers (the actual number were changed for privacy reasons)\n",
    "</ul>\n",
    "\n",
    "The goal is to predict the <code>log_PAX</code> column. The prediction quality is measured by RMSE. \n",
    "\n",
    "The data is obviously limited, but since data and location informations are available, it can be joined to external data sets. <b>The challenge in this RAMP is to find good data that can be correlated to flight traffic</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#added by Martha\n",
    "from sklearn import ensemble \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset using pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you will create a submission, `ramp-workflow` will load the data for you and split into a data matrix `X` and a target vector `y`. It will also take care about splitting the data into a training and testing set. These utilities are available in the module `problem.py` which we will load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `get_train_data()` loads the training data and returns a pandas dataframe `X` and a numpy vector `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = problem.get_train_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the information of the data `X`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8902 entries, 0 to 8901\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   DateOfDeparture   8902 non-null   object \n",
      " 1   Departure         8902 non-null   object \n",
      " 2   Arrival           8902 non-null   object \n",
      " 3   WeeksToDeparture  8902 non-null   float64\n",
      " 4   std_wtd           8902 non-null   float64\n",
      "dtypes: float64(2), object(3)\n",
      "memory usage: 347.9+ KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8902, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "def _encode_dates(X):\n",
    "    # With pandas < 1.0, we wil get a SettingWithCopyWarning\n",
    "    # In our case, we will avoid this warning by triggering a copy\n",
    "    # More information can be found at:\n",
    "    # https://github.com/scikit-learn/scikit-learn/issues/16191\n",
    "    X_encoded = X.copy()\n",
    "\n",
    "    # Make sure that DateOfDeparture is of datetime format\n",
    "    X_encoded.loc[:, 'DateOfDeparture'] = pd.to_datetime(X_encoded['DateOfDeparture'])\n",
    "    # Encode the DateOfDeparture\n",
    "    X_encoded.loc[:, 'year'] = X_encoded['DateOfDeparture'].dt.year\n",
    "    X_encoded.loc[:, 'month'] = X_encoded['DateOfDeparture'].dt.month\n",
    "    X_encoded.loc[:, 'day'] = X_encoded['DateOfDeparture'].dt.day\n",
    "    X_encoded.loc[:, 'weekday'] = X_encoded['DateOfDeparture'].dt.weekday\n",
    "    X_encoded.loc[:, 'week'] = X_encoded['DateOfDeparture'].dt.week\n",
    "    X_encoded.loc[:, 'n_days'] = X_encoded['DateOfDeparture'].apply(\n",
    "        lambda date: (date - pd.to_datetime(\"1970-01-01\")).days\n",
    "    )\n",
    "    # Once we did the encoding, we will not need DateOfDeparture\n",
    "    return X_encoded.drop(columns=[\"DateOfDeparture\"])\n",
    "\n",
    "date_encoder = FunctionTransformer(_encode_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Departure</th>\n",
       "      <th>Arrival</th>\n",
       "      <th>WeeksToDeparture</th>\n",
       "      <th>std_wtd</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>week</th>\n",
       "      <th>n_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORD</td>\n",
       "      <td>DFW</td>\n",
       "      <td>12.875000</td>\n",
       "      <td>9.812647</td>\n",
       "      <td>2012</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>15510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LAS</td>\n",
       "      <td>DEN</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>9.466734</td>\n",
       "      <td>2012</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>15593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DEN</td>\n",
       "      <td>LAX</td>\n",
       "      <td>10.863636</td>\n",
       "      <td>9.035883</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>15618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATL</td>\n",
       "      <td>ORD</td>\n",
       "      <td>11.480000</td>\n",
       "      <td>7.990202</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>15256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DEN</td>\n",
       "      <td>SFO</td>\n",
       "      <td>11.450000</td>\n",
       "      <td>9.517159</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>15391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Departure Arrival  WeeksToDeparture   std_wtd  year  month  day  weekday  \\\n",
       "0       ORD     DFW         12.875000  9.812647  2012      6   19        1   \n",
       "1       LAS     DEN         14.285714  9.466734  2012      9   10        0   \n",
       "2       DEN     LAX         10.863636  9.035883  2012     10    5        4   \n",
       "3       ATL     ORD         11.480000  7.990202  2011     10    9        6   \n",
       "4       DEN     SFO         11.450000  9.517159  2012      2   21        1   \n",
       "\n",
       "   week  n_days  \n",
       "0    25   15510  \n",
       "1    37   15593  \n",
       "2    40   15618  \n",
       "3    40   15256  \n",
       "4     8   15391  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_encoder.fit_transform(X).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regressor\n",
    "\n",
    "When dealing with a linear model, we need to one-hot encode categorical variables instead of ordinal encoding and standardize numerical variables. Thus we will:\n",
    "\n",
    "- encode the date;\n",
    "- then, one-hot encode all categorical columns, including the encoded date as well;\n",
    "- standardize the numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "date_encoder = FunctionTransformer(_encode_dates)\n",
    "date_cols = [\"DateOfDeparture\"]\n",
    "\n",
    "categorical_encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "categorical_cols = [\n",
    "    \"Arrival\", \"Departure\", \"year\", \"month\", \"day\",\n",
    "    \"weekday\", \"week\", \"n_days\"\n",
    "]\n",
    "\n",
    "numerical_scaler = StandardScaler() #when do I want to do this\n",
    "numerical_cols = [\"WeeksToDeparture\", \"std_wtd\"]\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (categorical_encoder, categorical_cols),\n",
    "    (numerical_scaler, numerical_cols)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now combine our `preprocessor` with the `LinearRegression` estimator in a `Pipeline`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regressor = LinearRegression()\n",
    "\n",
    "pipeline = make_pipeline(date_encoder, preprocessor, regressor) \n",
    "#first the date data is split, then onehotencoded and scaled, and then the regression is applied\n",
    "pipeline.fit(X,y)\n",
    "y_pred = pipeline.predict(X_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can evaluate our linear-model pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.6117 +/- 0.0149\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(\n",
    "    pipeline, X, y, cv=5, scoring='neg_mean_squared_error'\n",
    ")\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "print(\n",
    "    f\"RMSE: {np.mean(rmse_scores):.4f} +/- {np.std(rmse_scores):.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tests Martha**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensembles are constructed from decision tree models. Trees are added one at a time to the ensemble and fit to correct the prediction errors made by prior models. This is a type of ensemble machine learning model referred to as boosting.\n",
    "Recall that decision trees are added to the model sequentially in an effort to correct and improve upon the predictions made by prior trees (more trees require lower learning rate)\n",
    "Using fewer samples introduces more variance for each tree, although it can improve the overall performance of the model.(sub_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': 2000, #number of decision trees \n",
    "          'subsample': 1,\n",
    "          'max_depth': 8,\n",
    "          'min_samples_split': 5,\n",
    "          'learning_rate': 0.01,\n",
    "          'loss': 'ls'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('functiontransformer',\n",
       "                 FunctionTransformer(func=<function _encode_dates at 0x7ff00126cd30>)),\n",
       "                ('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('onehotencoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['Arrival', 'Departure',\n",
       "                                                   'year', 'month', 'day',\n",
       "                                                   'weekday', 'week',\n",
       "                                                   'n_days']),\n",
       "                                                 ('standardscaler',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['WeeksToDeparture',\n",
       "                                                   'std_wtd'])])),\n",
       "                ('gradientboostingregressor',\n",
       "                 GradientBoostingRegressor(learning_rate=0.01, max_depth=8,\n",
       "                                           min_samples_split=5,\n",
       "                                           n_estimators=2000, subsample=1))])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import ensemble \n",
    "\n",
    "regressor2 = ensemble.GradientBoostingRegressor(**params)\n",
    "\n",
    "pipeline2 = make_pipeline(date_encoder, preprocessor, regressor2)\n",
    "pipeline2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.4066 +/- 0.0202\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(\n",
    "    pipeline2, X, y, cv=5, scoring='neg_mean_squared_error'\n",
    ")\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "print(\n",
    "    f\"RMSE: {np.mean(rmse_scores):.4f} +/- {np.std(rmse_scores):.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "pipeline2 = make_pipeline(date_encoder, preprocessor, regressor2)\n",
    "\n",
    "space = dict()\n",
    "space['gradientboostingregressor__n_estimators'] = [10, 500, 1000, 2000]\n",
    "space['gradientboostingregressor__subsample'] = [0.5, 0.7, 1.0]\n",
    "space['gradientboostingregressor__max_depth'] = [2, 5, 8]\n",
    "space['gradientboostingregressor__learning_rate'] = [0.001, 0.01, 0.1, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = RandomizedSearchCV(pipeline2, param_distributions=space, verbose=8)\n",
    "search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame(search.cv_results_)\n",
    "#scores_df = scores.sort(columns=['rank_test_score']).reset_index(drop='index')\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space2 = dict()\n",
    "space['gradientboostingregressor__min_samples_split'] = [0.1, 0.3, 0.8, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search2 = RandomizedSearchCV(pipeline2, param_distributions=space2, verbose=8)\n",
    "search2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df2 = pd.DataFrame(search2.cv_results_)\n",
    "#scores_df = scores.sort(columns=['rank_test_score']).reset_index(drop='index')\n",
    "scores_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Martha, adding data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source of airport info: https://openflights.org/data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'submissions/starting_kit/airport_geolocation.csv'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# when submitting a kit, the `__file__` variable will corresponds to the\n",
    "# path to `estimator.py`. However, this variable is not defined in the\n",
    "# notebook and thus we must define the `__file__` variable to imitate\n",
    "# how a submission `.py` would work.\n",
    "__file__ = os.path.join('submissions', 'starting_kit', 'estimator.py')\n",
    "filepath = os.path.join(os.path.dirname(__file__), 'airport_geolocation.csv')\n",
    "filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File airport_geolocation.csv does not exist: 'airport_geolocation.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/Desktop/Python_Labs/Python_final_project/air_passenger_traffic/submissions/starting_kit/estimator.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'airport_geolocation.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File airport_geolocation.csv does not exist: 'airport_geolocation.csv'"
     ]
    }
   ],
   "source": [
    "pd.read_csv('airport_geolocation.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _merge_external_data(X):\n",
    "    X = X.copy()  # to avoid raising SettingOnCopyWarning\n",
    "    # Make sure that DateOfDeparture is of dtype datetime\n",
    "    X.loc[:, \"DateOfDeparture\"] = pd.to_datetime(X['DateOfDeparture'])\n",
    "    data_geolocation = pd.read_csv('airport_geolocation.csv')\n",
    "    data_geolocation = data_geolocation[['IATA', 'Latitude', 'Longitude']]\n",
    "    data_geolocation = data_geolocation.rename(columns={'IATA': 'Departure', 'Latitude': 'Latitude', 'Longitude': 'Longitude'})\n",
    "    X_merged = pd.merge(\n",
    "        X, data_geolocation, how='left', on=['Departure'], sort=False\n",
    "    )\n",
    "    return X_merged\n",
    "\n",
    "data_merger = FunctionTransformer(_merge_external_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merger.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline3 = make_pipeline(data_merger, date_encoder, preprocessor, regressor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(\n",
    "    pipeline3, X, y, cv=5, scoring='neg_mean_squared_error'\n",
    ")\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "print(\n",
    "    f\"RMSE: {np.mean(rmse_scores):.4f} +/- {np.std(rmse_scores):.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XG Boost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_nicolas = pd.read_csv('testemoica.csv')\n",
    "dat_nicolas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _merge_external_data_N(X):\n",
    "    X = X.copy()  # to avoid raising SettingOnCopyWarning\n",
    "    # Make sure that DateOfDeparture is of dtype datetime\n",
    "    X.loc[:, \"DateOfDeparture\"] = pd.to_datetime(X['DateOfDeparture'])\n",
    "    data_nicolas = pd.read_csv('testemoica.csv')\n",
    "    data_nicolas = data_nicolas[['Departure', 'Arrival', 'WeeksToDeparture', 'std_wtd', 'year', 'month', 'day', 'weekday', 'week', 'n_days', 'passengers load', 'distance km']]\n",
    "    X_merged = pd.merge(\n",
    "        X, data_nicolas, how='left', left_index=True, right_index=True #on=[['Departure', 'Arrival', 'year', 'month', 'day']], sort=False\n",
    "    )\n",
    "    X_merged = X_merged[['DateOfDeparture', 'Departure_x', 'Arrival_x', 'WeeksToDeparture_x', 'std_wtd_x', 'year', 'month', 'day', 'weekday', 'week', 'n_days', 'passengers load', 'distance km']]\n",
    "    X_merged = X_merged.rename(\n",
    "             columns={'DateOfDeparture':'DateOfDeparture', 'Departure_x':'Departure', 'Arrival_x':'Arrival', 'WeeksToDeparture_x':'WeeksToDeparture', 'std_wtd_x':'std_wtd_x', 'year':'year', 'month':'month', 'day':'day', 'weekday':'weekday', 'week':'week', 'n_days':'n_days', 'passengers load':'passsengers_load', 'distance km':'distance_km'}\n",
    "              )\n",
    "    return X_merged\n",
    "\n",
    "data_merger_N = FunctionTransformer(_merge_external_data_N)\n",
    "data_merger_N.fit_transform(X).head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "date_encoder = FunctionTransformer(_encode_dates)\n",
    "date_cols = [\"DateOfDeparture\"]\n",
    "\n",
    "categorical_encoder = OrdinalEncoder()\n",
    "categorical_cols = [\"Arrival\", \"Departure\"]\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (date_encoder, date_cols),\n",
    "    (categorical_encoder, categorical_cols),\n",
    "    remainder='passthrough',  # passthrough numerical columns as they are\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xgb_r = xgb.XGBRegressor(objective ='reg:linear', \n",
    "                  n_estimators = 1000, seed = 123, max_depth = 8)\n",
    "pipeline4 = make_pipeline(data_merger_N, preprocessor, xgb_r)\n",
    "pipeline4.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(\n",
    "    pipeline4, X, y, cv=5, scoring='neg_mean_squared_error'\n",
    ")\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "print(\n",
    "    f\"RMSE: {np.mean(rmse_scores):.4f} +/- {np.std(rmse_scores):.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xgb_r = xgb.XGBRegressor(n_estimators = 500, max_depth = 4)\n",
    "pipeline5 = make_pipeline(data_merger_N, preprocessor, xgb_r)\n",
    "pipeline5.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(\n",
    "    pipeline5, X, y, cv=5, scoring='neg_mean_squared_error'\n",
    ")\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "print(\n",
    "    f\"RMSE: {np.mean(rmse_scores):.4f} +/- {np.std(rmse_scores):.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_xgb = {'n_estimators': 2000, #number of decision trees \n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_xgb = dict()\n",
    "space_xgb['xgbregressor__n_estimators'] = [500, 1000, 2000, 5000]\n",
    "space_xgb['xgbregressor__max_depth'] = [2, 4, 6, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = RandomizedSearchCV(pipeline5, param_distributions=space_xgb, verbose=8)\n",
    "search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame(search.cv_results_)\n",
    "#scores_df = scores.sort(columns=['rank_test_score']).reset_index(drop='index')\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient Boost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': 2000, #number of decision trees \n",
    "          'subsample': 0.5,\n",
    "          'max_depth': 8,\n",
    "          'min_samples_split': 5,\n",
    "          'learning_rate': 0.01,\n",
    "          'loss': 'ls'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_merger_N' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-f1b32274e735>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mGradBoost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientBoostingRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpipeline6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_merger_N\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGradBoost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mpipeline6\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_merger_N' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble \n",
    "\n",
    "GradBoost = ensemble.GradientBoostingRegressor(**params)\n",
    "\n",
    "pipeline6 = make_pipeline(data_merger_N, preprocessor, GradBoost)\n",
    "pipeline6.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(\n",
    "    pipeline6, X, y, cv=5, scoring='neg_mean_squared_error'\n",
    ")\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "print(\n",
    "    f\"RMSE: {np.mean(rmse_scores):.4f} +/- {np.std(rmse_scores):.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "space = dict()\n",
    "space['gradientboostingregressor__n_estimators'] = [500, 1000, 2000]\n",
    "space['gradientboostingregressor__subsample'] = [0.5, 0.7, 1.0]\n",
    "space['gradientboostingregressor__max_depth'] = [2, 5, 8]\n",
    "space['gradientboostingregressor__learning_rate'] = [0.001, 0.01, 0.1, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = RandomizedSearchCV(pipeline6, param_distributions=space, verbose=8)\n",
    "search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame(search.cv_results_)\n",
    "#scores_df = scores.sort(columns=['rank_test_score']).reset_index(drop='index')\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_jobs=-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merge 2 datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _merge_external_data_2(X):\n",
    "    X = X.copy()  # to avoid raising SettingOnCopyWarning\n",
    "    # Make sure that DateOfDeparture is of dtype datetime\n",
    "    X.loc[:, \"DateOfDeparture\"] = pd.to_datetime(X['DateOfDeparture'])\n",
    "    \n",
    "    #merging dataset 1\n",
    "    data_nicolas = pd.read_csv('testemoica.csv')\n",
    "    data_nicolas = data_nicolas[['Departure', 'Arrival', 'WeeksToDeparture', 'std_wtd', 'year', 'month', 'day', 'weekday', 'week', 'n_days', 'passengers load', 'distance km']]\n",
    "    X_merged = pd.merge(\n",
    "        X, data_nicolas, how='left', left_index=True, right_index=True #on=[['Departure', 'Arrival', 'year', 'month', 'day']], sort=False\n",
    "    )\n",
    "    X_merged = X_merged[['DateOfDeparture', 'Departure_x', 'Arrival_x', 'WeeksToDeparture_x', 'std_wtd_x', 'year', 'month', 'day', 'weekday', 'week', 'n_days', 'passengers load', 'distance km']]\n",
    "    X_merged = X_merged.rename(\n",
    "             columns={'DateOfDeparture':'DateOfDeparture', 'Departure_x':'Departure', 'Arrival_x':'Arrival', 'WeeksToDeparture_x':'WeeksToDeparture', 'std_wtd_x':'std_wtd_x', 'year':'year', 'month':'month', 'day':'day', 'weekday':'weekday', 'week':'week', 'n_days':'n_days', 'passengers load':'enplanement', 'distance km':'distance_km'}\n",
    "              )\n",
    "    \n",
    "    #merging dataset 2\n",
    "    data_temp = pd.read_csv('external_data.csv', parse_dates=[\"Date\"])\n",
    "    data_temp = data_temp[['Date', 'AirPort', 'Max TemperatureC']]\n",
    "    data_temp = data_temp.rename(\n",
    "        columns={'Date': 'DateOfDeparture', 'AirPort': 'Arrival'})\n",
    "    X_merged2 = pd.merge(\n",
    "        X_merged, data_temp, how='left', on=['DateOfDeparture', 'Arrival'], sort=False\n",
    "    )\n",
    "    return X_merged2\n",
    "\n",
    "data_merger_2= FunctionTransformer(_merge_external_data_2)\n",
    "data_merger_2.fit_transform(X).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GradientBoost with 2 datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_GB_2 = {'n_estimators': 1000, #number of decision trees \n",
    "          'subsample': 0.7,\n",
    "          'max_depth': 8,\n",
    "          'min_samples_split': 5,\n",
    "          'learning_rate': 0.01,\n",
    "          'loss': 'ls'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GradBoost_GB_2 = ensemble.GradientBoostingRegressor(**params_GB_2)\n",
    "\n",
    "pipeline7 = make_pipeline(data_merger_2, preprocessor, GradBoost_GB_2)\n",
    "pipeline7.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(\n",
    "    pipeline7, X, y, cv=5, scoring='neg_mean_squared_error'\n",
    ")\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "print(\n",
    "    f\"RMSE: {np.mean(rmse_scores):.4f} +/- {np.std(rmse_scores):.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = RandomizedSearchCV(pipeline7, param_distributions=space, verbose=8)\n",
    "search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame(search.cv_results_)\n",
    "#scores_df = scores.sort(columns=['rank_test_score']).reset_index(drop='index')\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merge enplanment, distance, GDP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Departure</th>\n",
       "      <th>Arrival</th>\n",
       "      <th>WeeksToDeparture</th>\n",
       "      <th>std_wtd</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>week</th>\n",
       "      <th>n_days</th>\n",
       "      <th>enplanement</th>\n",
       "      <th>distance_km</th>\n",
       "      <th>gdp_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORD</td>\n",
       "      <td>DFW</td>\n",
       "      <td>12.875000</td>\n",
       "      <td>9.812647</td>\n",
       "      <td>2012</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>15510</td>\n",
       "      <td>32171795.0</td>\n",
       "      <td>1290.179371</td>\n",
       "      <td>122113683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LAS</td>\n",
       "      <td>DEN</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>9.466734</td>\n",
       "      <td>2012</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>15593</td>\n",
       "      <td>19959651.0</td>\n",
       "      <td>991.064058</td>\n",
       "      <td>16882965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DEN</td>\n",
       "      <td>LAX</td>\n",
       "      <td>10.863636</td>\n",
       "      <td>9.035883</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>15618</td>\n",
       "      <td>25799841.0</td>\n",
       "      <td>1366.918847</td>\n",
       "      <td>31449233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATL</td>\n",
       "      <td>ORD</td>\n",
       "      <td>11.480000</td>\n",
       "      <td>7.990202</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>15256</td>\n",
       "      <td>44414121.0</td>\n",
       "      <td>974.522557</td>\n",
       "      <td>52754957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DEN</td>\n",
       "      <td>SFO</td>\n",
       "      <td>11.450000</td>\n",
       "      <td>9.517159</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>15391</td>\n",
       "      <td>25799841.0</td>\n",
       "      <td>1538.142783</td>\n",
       "      <td>31449233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Departure Arrival  WeeksToDeparture   std_wtd  year  month  day  weekday  \\\n",
       "0       ORD     DFW         12.875000  9.812647  2012      6   19        1   \n",
       "1       LAS     DEN         14.285714  9.466734  2012      9   10        0   \n",
       "2       DEN     LAX         10.863636  9.035883  2012     10    5        4   \n",
       "3       ATL     ORD         11.480000  7.990202  2011     10    9        6   \n",
       "4       DEN     SFO         11.450000  9.517159  2012      2   21        1   \n",
       "\n",
       "   week  n_days  enplanement  distance_km     gdp_50  \n",
       "0    25   15510   32171795.0  1290.179371  122113683  \n",
       "1    37   15593   19959651.0   991.064058   16882965  \n",
       "2    40   15618   25799841.0  1366.918847   31449233  \n",
       "3    40   15256   44414121.0   974.522557   52754957  \n",
       "4     8   15391   25799841.0  1538.142783   31449233  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _merge_external_data_3(X):\n",
    "    X = X.copy()  # to avoid raising SettingOnCopyWarning\n",
    "    # Make sure that DateOfDeparture is of dtype datetime\n",
    "    X.loc[:, \"DateOfDeparture\"] = pd.to_datetime(X['DateOfDeparture'])\n",
    "    \n",
    "    #merging dataset 1\n",
    "    data_nicolas = pd.read_csv('testemoica.csv')\n",
    "    data_nicolas = data_nicolas[['Departure', 'Arrival', 'WeeksToDeparture', 'std_wtd', 'year', 'month', 'day', 'weekday', 'week', 'n_days', 'passengers load', 'distance km']]\n",
    "    X_merged = pd.merge(\n",
    "        X, data_nicolas, how='left', left_index=True, right_index=True #on=[['Departure', 'Arrival', 'year', 'month', 'day']], sort=False\n",
    "    )\n",
    "    X_merged = X_merged[['DateOfDeparture', 'Departure_x', 'Arrival_x', 'WeeksToDeparture_x', 'std_wtd_x', 'year', 'month', 'day', 'weekday', 'week', 'n_days', 'passengers load', 'distance km']]\n",
    "    X_merged = X_merged.rename(\n",
    "             columns={'DateOfDeparture':'DateOfDeparture', 'Departure_x':'Departure', 'Arrival_x':'Arrival', 'WeeksToDeparture_x':'WeeksToDeparture', 'std_wtd_x':'std_wtd', 'year':'year', 'month':'month', 'day':'day', 'weekday':'weekday', 'week':'week', 'n_days':'n_days', 'passengers load':'enplanement', 'distance km':'distance_km'}\n",
    "              )\n",
    "    \n",
    "    #merging dataset 2\n",
    "    data_gdp = pd.read_csv('gdp_naics.csv', parse_dates=[\"year\"])\n",
    "    data_gdp = data_gdp.rename(\n",
    "               columns={'year' : 'DateOfDeparture', 'airport' : 'Departure', 'gdp__50' : 'gdp_50', 'gdp_2' : 'gdp_2', 'gdp_1' : 'gdp_1' })\n",
    "    data_gdp = date_encoder.fit_transform(data_gdp)\n",
    "    data_gdp = data_gdp[['year', 'Departure', 'gdp_50']]\n",
    "    \n",
    "    X_merged2 = pd.merge(\n",
    "        X_merged, data_gdp, how='left', on=['year', 'Departure'], sort=False)\n",
    "    X_merged2 = X_merged2.drop('DateOfDeparture', axis=1) #dropped 'day', 'month', 'year'\n",
    "    return X_merged2\n",
    "\n",
    "data_merger_3= FunctionTransformer(_merge_external_data_3)\n",
    "data_merger_3.fit_transform(X).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_encoder = OrdinalEncoder()\n",
    "cat_cols_after_merge = [\"Arrival\", \"Departure\", \"year\", \"month\", \"day\", \"weekday\", \"week\"]\n",
    "\n",
    "numerical_scaler = StandardScaler()\n",
    "numerical_cols = [\"WeeksToDeparture\", \"std_wtd\", \"n_days\", \"enplanement\", \"distance_km\", \"gdp_50\"]\n",
    "\n",
    "prep_after_merge = make_column_transformer(\n",
    "    (categorical_encoder, cat_cols_after_merge),\n",
    "    (numerical_scaler, numerical_cols)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_GB_4 = {'n_estimators': 2000, #number of decision trees \n",
    "          'subsample': 1,\n",
    "          'max_depth': 5,\n",
    "          'min_samples_split': 5,\n",
    "          'learning_rate': 0.1,\n",
    "          'loss': 'ls'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('functiontransformer',\n",
       "                 FunctionTransformer(func=<function _merge_external_data_3 at 0x7ff0010ba1f0>)),\n",
       "                ('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('ordinalencoder',\n",
       "                                                  OrdinalEncoder(),\n",
       "                                                  ['Arrival', 'Departure',\n",
       "                                                   'year', 'month', 'day',\n",
       "                                                   'weekday', 'week']),\n",
       "                                                 ('standardscaler',\n",
       "                                                  StandardScaler(),\n",
       "                                                  ['WeeksToDeparture',\n",
       "                                                   'std_wtd', 'n_days',\n",
       "                                                   'enplanement', 'distance_km',\n",
       "                                                   'gdp_50'])])),\n",
       "                ('gradientboostingregressor',\n",
       "                 GradientBoostingRegressor(max_depth=5, min_samples_split=5,\n",
       "                                           n_estimators=2000, subsample=1))])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GradBoost_GB_4 = ensemble.GradientBoostingRegressor(**params_GB_4, n_jobs=-1)\n",
    "\n",
    "pipeline8 = make_pipeline(data_merger_3, prep_after_merge, GradBoost_GB_4)\n",
    "pipeline8.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.3628 +/- 0.0218\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(\n",
    "    pipeline8, X, y, cv=5, scoring='neg_mean_squared_error'\n",
    ")\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "print(\n",
    "    f\"RMSE: {np.mean(rmse_scores):.4f} +/- {np.std(rmse_scores):.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = dict()\n",
    "space['gradientboostingregressor__n_estimators'] = [500, 1000, 2000]\n",
    "space['gradientboostingregressor__subsample'] = [0.5, 0.7, 1.0]\n",
    "space['gradientboostingregressor__max_depth'] = [2, 5, 8]\n",
    "space['gradientboostingregressor__learning_rate'] = [0.001, 0.01, 0.1, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01, score=0.871, total=  22.9s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   22.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01, score=0.853, total=  23.5s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   46.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01, score=0.865, total=  24.0s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  1.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01, score=0.842, total=  24.4s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  1.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01, score=0.870, total=  24.7s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.001 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.001, score=0.742, total=  51.6s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.001 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  2.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.001, score=0.725, total=  52.6s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.001 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  3.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.001, score=0.739, total=  52.5s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.001 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.001, score=0.728, total=  52.2s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.001 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.001, score=0.742, total=  52.2s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=0.01, score=0.587, total=   5.7s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=0.01, score=0.570, total=   5.8s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=0.01, score=0.582, total=   5.8s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=0.01, score=0.569, total=   5.8s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=0.01, score=0.587, total=   5.8s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=1.0 \n",
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=1.0, score=0.283, total=   9.8s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=1.0 \n",
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=1.0, score=0.228, total=   9.7s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=1.0 \n",
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=1.0, score=0.262, total=   9.7s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=1.0 \n",
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=1.0, score=0.296, total=   9.7s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=1.0 \n",
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=1.0, score=0.282, total=   9.8s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01, score=0.861, total=  33.3s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01, score=0.844, total=  33.0s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01, score=0.857, total=  33.0s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01, score=0.836, total=  33.1s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01, score=0.861, total=  33.1s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.1 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.1, score=0.872, total= 6.2min\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.1 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.1, score=0.862, total=  29.8s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.1 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.1, score=0.873, total=  31.3s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.1 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.1, score=0.852, total=  32.4s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.1, score=0.874, total=  33.2s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.1 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.1, score=0.864, total=  53.2s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.1 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.1, score=0.853, total=  53.5s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.1 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.1, score=0.860, total=  53.9s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.1 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.1, score=0.841, total=  53.4s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.1 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.1, score=0.862, total=  53.3s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.01, score=0.845, total=  13.0s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.01, score=0.832, total=  13.0s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.01, score=0.839, total=  13.1s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.01, score=0.821, total=  13.0s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.01, score=0.839, total=  13.1s\n",
      "[CV] gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=1.0 \n",
      "[CV]  gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=1.0, score=-12.643, total=   7.2s\n",
      "[CV] gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=1.0 \n",
      "[CV]  gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=1.0, score=-8.470, total=   7.3s\n",
      "[CV] gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=1.0 \n",
      "[CV]  gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=1.0, score=-6.320, total=   7.3s\n",
      "[CV] gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=1.0 \n",
      "[CV]  gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=1.0, score=-7.463, total=   7.2s\n",
      "[CV] gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=1.0 \n",
      "[CV]  gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=1.0, score=-9.929, total=   7.2s\n",
      "[CV] gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.01, score=0.874, total=  14.3s\n",
      "[CV] gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.01, score=0.857, total=  14.3s\n",
      "[CV] gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.01, score=0.866, total=  14.3s\n",
      "[CV] gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.01, score=0.844, total=  14.4s\n",
      "[CV] gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.01, score=0.872, total=  14.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed: 26.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=Pipeline(steps=[('functiontransformer',\n",
       "                                              FunctionTransformer(func=<function _merge_external_data_3 at 0x7ff0010ba1f0>)),\n",
       "                                             ('columntransformer',\n",
       "                                              ColumnTransformer(transformers=[('ordinalencoder',\n",
       "                                                                               OrdinalEncoder(),\n",
       "                                                                               ['Arrival',\n",
       "                                                                                'Departure',\n",
       "                                                                                'year',\n",
       "                                                                                'month',\n",
       "                                                                                'day',\n",
       "                                                                                'weekday',\n",
       "                                                                                'week']),\n",
       "                                                                              ('standardscaler',\n",
       "                                                                               StandardScaler(),\n",
       "                                                                               ['WeeksToDeparture',...\n",
       "                                             ('gradientboostingregressor',\n",
       "                                              GradientBoostingRegressor(max_depth=5,\n",
       "                                                                        min_samples_split=5,\n",
       "                                                                        n_estimators=500,\n",
       "                                                                        subsample=0.5))]),\n",
       "                   param_distributions={'gradientboostingregressor__learning_rate': [0.001,\n",
       "                                                                                     0.01,\n",
       "                                                                                     0.1,\n",
       "                                                                                     1.0],\n",
       "                                        'gradientboostingregressor__max_depth': [2,\n",
       "                                                                                 5,\n",
       "                                                                                 8],\n",
       "                                        'gradientboostingregressor__n_estimators': [500,\n",
       "                                                                                    1000,\n",
       "                                                                                    2000],\n",
       "                                        'gradientboostingregressor__subsample': [0.5,\n",
       "                                                                                 0.7,\n",
       "                                                                                 1.0]},\n",
       "                   verbose=8)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = RandomizedSearchCV(pipeline8, param_distributions=space, verbose=8)\n",
    "search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_gradientboostingregressor__subsample</th>\n",
       "      <th>param_gradientboostingregressor__n_estimators</th>\n",
       "      <th>param_gradientboostingregressor__max_depth</th>\n",
       "      <th>param_gradientboostingregressor__learning_rate</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.761567</td>\n",
       "      <td>0.644891</td>\n",
       "      <td>0.129960</td>\n",
       "      <td>0.005657</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'gradientboostingregressor__subsample': 0.7, ...</td>\n",
       "      <td>0.871069</td>\n",
       "      <td>0.852744</td>\n",
       "      <td>0.865239</td>\n",
       "      <td>0.842077</td>\n",
       "      <td>0.869773</td>\n",
       "      <td>0.860180</td>\n",
       "      <td>0.011128</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51.995570</td>\n",
       "      <td>0.317528</td>\n",
       "      <td>0.226425</td>\n",
       "      <td>0.006290</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'gradientboostingregressor__subsample': 1.0, ...</td>\n",
       "      <td>0.741724</td>\n",
       "      <td>0.724616</td>\n",
       "      <td>0.739411</td>\n",
       "      <td>0.727743</td>\n",
       "      <td>0.742248</td>\n",
       "      <td>0.735148</td>\n",
       "      <td>0.007451</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.685048</td>\n",
       "      <td>0.034616</td>\n",
       "      <td>0.063179</td>\n",
       "      <td>0.004410</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'gradientboostingregressor__subsample': 0.7, ...</td>\n",
       "      <td>0.586536</td>\n",
       "      <td>0.569748</td>\n",
       "      <td>0.581977</td>\n",
       "      <td>0.568629</td>\n",
       "      <td>0.586776</td>\n",
       "      <td>0.578733</td>\n",
       "      <td>0.007986</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.657457</td>\n",
       "      <td>0.059231</td>\n",
       "      <td>0.083368</td>\n",
       "      <td>0.003330</td>\n",
       "      <td>0.7</td>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>{'gradientboostingregressor__subsample': 0.7, ...</td>\n",
       "      <td>0.282575</td>\n",
       "      <td>0.228171</td>\n",
       "      <td>0.261819</td>\n",
       "      <td>0.295708</td>\n",
       "      <td>0.282428</td>\n",
       "      <td>0.270140</td>\n",
       "      <td>0.023622</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.968123</td>\n",
       "      <td>0.098794</td>\n",
       "      <td>0.129340</td>\n",
       "      <td>0.004601</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'gradientboostingregressor__subsample': 1.0, ...</td>\n",
       "      <td>0.860935</td>\n",
       "      <td>0.844055</td>\n",
       "      <td>0.857173</td>\n",
       "      <td>0.835546</td>\n",
       "      <td>0.861310</td>\n",
       "      <td>0.851804</td>\n",
       "      <td>0.010266</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>99.823395</td>\n",
       "      <td>136.530031</td>\n",
       "      <td>0.113974</td>\n",
       "      <td>0.018907</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'gradientboostingregressor__subsample': 1.0, ...</td>\n",
       "      <td>0.871708</td>\n",
       "      <td>0.862485</td>\n",
       "      <td>0.873010</td>\n",
       "      <td>0.852380</td>\n",
       "      <td>0.874172</td>\n",
       "      <td>0.866751</td>\n",
       "      <td>0.008289</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>53.281067</td>\n",
       "      <td>0.240217</td>\n",
       "      <td>0.153696</td>\n",
       "      <td>0.002739</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'gradientboostingregressor__subsample': 1.0, ...</td>\n",
       "      <td>0.864370</td>\n",
       "      <td>0.852910</td>\n",
       "      <td>0.859566</td>\n",
       "      <td>0.840504</td>\n",
       "      <td>0.862374</td>\n",
       "      <td>0.855945</td>\n",
       "      <td>0.008638</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.963186</td>\n",
       "      <td>0.053693</td>\n",
       "      <td>0.092044</td>\n",
       "      <td>0.002539</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'gradientboostingregressor__subsample': 1.0, ...</td>\n",
       "      <td>0.844700</td>\n",
       "      <td>0.832158</td>\n",
       "      <td>0.838533</td>\n",
       "      <td>0.820540</td>\n",
       "      <td>0.838903</td>\n",
       "      <td>0.834967</td>\n",
       "      <td>0.008234</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.165799</td>\n",
       "      <td>0.027434</td>\n",
       "      <td>0.077872</td>\n",
       "      <td>0.002172</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>{'gradientboostingregressor__subsample': 0.5, ...</td>\n",
       "      <td>-12.643038</td>\n",
       "      <td>-8.469739</td>\n",
       "      <td>-6.319916</td>\n",
       "      <td>-7.463495</td>\n",
       "      <td>-9.928944</td>\n",
       "      <td>-8.965026</td>\n",
       "      <td>2.188763</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14.177581</td>\n",
       "      <td>0.036300</td>\n",
       "      <td>0.128506</td>\n",
       "      <td>0.005474</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'gradientboostingregressor__subsample': 0.5, ...</td>\n",
       "      <td>0.874167</td>\n",
       "      <td>0.856835</td>\n",
       "      <td>0.866198</td>\n",
       "      <td>0.843824</td>\n",
       "      <td>0.872267</td>\n",
       "      <td>0.862658</td>\n",
       "      <td>0.011189</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      23.761567      0.644891         0.129960        0.005657   \n",
       "1      51.995570      0.317528         0.226425        0.006290   \n",
       "2       5.685048      0.034616         0.063179        0.004410   \n",
       "3       9.657457      0.059231         0.083368        0.003330   \n",
       "4      32.968123      0.098794         0.129340        0.004601   \n",
       "5      99.823395    136.530031         0.113974        0.018907   \n",
       "6      53.281067      0.240217         0.153696        0.002739   \n",
       "7      12.963186      0.053693         0.092044        0.002539   \n",
       "8       7.165799      0.027434         0.077872        0.002172   \n",
       "9      14.177581      0.036300         0.128506        0.005474   \n",
       "\n",
       "  param_gradientboostingregressor__subsample  \\\n",
       "0                                        0.7   \n",
       "1                                          1   \n",
       "2                                        0.7   \n",
       "3                                        0.7   \n",
       "4                                          1   \n",
       "5                                          1   \n",
       "6                                          1   \n",
       "7                                          1   \n",
       "8                                        0.5   \n",
       "9                                        0.5   \n",
       "\n",
       "  param_gradientboostingregressor__n_estimators  \\\n",
       "0                                          2000   \n",
       "1                                          2000   \n",
       "2                                          1000   \n",
       "3                                           500   \n",
       "4                                          2000   \n",
       "5                                          2000   \n",
       "6                                          2000   \n",
       "7                                           500   \n",
       "8                                           500   \n",
       "9                                          1000   \n",
       "\n",
       "  param_gradientboostingregressor__max_depth  \\\n",
       "0                                          5   \n",
       "1                                          8   \n",
       "2                                          2   \n",
       "3                                          8   \n",
       "4                                          5   \n",
       "5                                          5   \n",
       "6                                          8   \n",
       "7                                          8   \n",
       "8                                          8   \n",
       "9                                          8   \n",
       "\n",
       "  param_gradientboostingregressor__learning_rate  \\\n",
       "0                                           0.01   \n",
       "1                                          0.001   \n",
       "2                                           0.01   \n",
       "3                                              1   \n",
       "4                                           0.01   \n",
       "5                                            0.1   \n",
       "6                                            0.1   \n",
       "7                                           0.01   \n",
       "8                                              1   \n",
       "9                                           0.01   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'gradientboostingregressor__subsample': 0.7, ...           0.871069   \n",
       "1  {'gradientboostingregressor__subsample': 1.0, ...           0.741724   \n",
       "2  {'gradientboostingregressor__subsample': 0.7, ...           0.586536   \n",
       "3  {'gradientboostingregressor__subsample': 0.7, ...           0.282575   \n",
       "4  {'gradientboostingregressor__subsample': 1.0, ...           0.860935   \n",
       "5  {'gradientboostingregressor__subsample': 1.0, ...           0.871708   \n",
       "6  {'gradientboostingregressor__subsample': 1.0, ...           0.864370   \n",
       "7  {'gradientboostingregressor__subsample': 1.0, ...           0.844700   \n",
       "8  {'gradientboostingregressor__subsample': 0.5, ...         -12.643038   \n",
       "9  {'gradientboostingregressor__subsample': 0.5, ...           0.874167   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.852744           0.865239           0.842077           0.869773   \n",
       "1           0.724616           0.739411           0.727743           0.742248   \n",
       "2           0.569748           0.581977           0.568629           0.586776   \n",
       "3           0.228171           0.261819           0.295708           0.282428   \n",
       "4           0.844055           0.857173           0.835546           0.861310   \n",
       "5           0.862485           0.873010           0.852380           0.874172   \n",
       "6           0.852910           0.859566           0.840504           0.862374   \n",
       "7           0.832158           0.838533           0.820540           0.838903   \n",
       "8          -8.469739          -6.319916          -7.463495          -9.928944   \n",
       "9           0.856835           0.866198           0.843824           0.872267   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.860180        0.011128                3  \n",
       "1         0.735148        0.007451                7  \n",
       "2         0.578733        0.007986                8  \n",
       "3         0.270140        0.023622                9  \n",
       "4         0.851804        0.010266                5  \n",
       "5         0.866751        0.008289                1  \n",
       "6         0.855945        0.008638                4  \n",
       "7         0.834967        0.008234                6  \n",
       "8        -8.965026        2.188763               10  \n",
       "9         0.862658        0.011189                2  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(search.cv_results_)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('functiontransformer',\n",
       "                 FunctionTransformer(func=<function _merge_external_data_3 at 0x7fefe6903ee0>)),\n",
       "                ('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('ordinalencoder',\n",
       "                                                  OrdinalEncoder(),\n",
       "                                                  ['Arrival', 'Departure',\n",
       "                                                   'year', 'month', 'day',\n",
       "                                                   'weekday', 'week'])]))])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline8[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep = pipeline8[:-1]\n",
    "predictor = pipeline8[-1]\n",
    "\n",
    "X_augmented = prep.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WRONG\n",
    "#categorical_cols_name = cat_cols_after_merge\n",
    "#numerical_cols_name = (pipeline8[0].transform(X)\n",
    "                                  .columns[pipeline8[1].transformers_[-1][-1]]\n",
    "                                  .tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Arrival', 'Departure', 'year', 'month', 'day', 'weekday', 'week',\n",
       "       'WeeksToDeparture', 'std_wtd', 'n_days', 'enplanement',\n",
       "       'distance_km', 'gdp_50'], dtype='<U16')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#WRONG\n",
    "feature_names = np.array(\n",
    "    cat_cols_after_merge + numerical_cols\n",
    ")\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.00000000e+00, 1.50000000e+01, 1.00000000e+00, ...,\n",
       "        3.21717950e+07, 1.29017937e+03, 1.22113683e+08],\n",
       "       [3.00000000e+00, 9.00000000e+00, 1.00000000e+00, ...,\n",
       "        1.99596510e+07, 9.91064058e+02, 1.68829650e+07],\n",
       "       [1.00000000e+01, 3.00000000e+00, 1.00000000e+00, ...,\n",
       "        2.57998410e+07, 1.36691885e+03, 3.14492330e+07],\n",
       "       ...,\n",
       "       [9.00000000e+00, 1.90000000e+01, 1.00000000e+00, ...,\n",
       "        2.12842360e+07, 6.66231262e+02, 8.11760420e+07],\n",
       "       [1.60000000e+01, 1.50000000e+01, 2.00000000e+00, ...,\n",
       "        0.00000000e+00, 1.09052113e+03, 1.24360342e+08],\n",
       "       [0.00000000e+00, 5.00000000e+00, 0.00000000e+00, ...,\n",
       "        1.57168650e+07, 9.56603417e+02, 3.28756280e+07]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(max_depth=5, min_samples_split=5, n_estimators=500,\n",
       "                          subsample=0.5)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.fit(X_augmented,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "feature_importances = permutation_importance(\n",
    "    predictor.fit(X_augmented,y), X_augmented, y, n_repeats=10, n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sorted_idx = feature_importances.importances_mean.argsort()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(feature_importances.importances[sorted_idx].T,\n",
    "           vert=False, labels=feature_names[sorted_idx])\n",
    "ax.set_title(\"Permutation Importances (train set)\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
