{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a href=\"http://www.datascience-paris-saclay.fr\">Paris Saclay Center for Data Science</a>\n",
    "# <a href=https://www.ramp.studio/problems/air_passengers>RAMP</a> on predicting the number of air passengers\n",
    "\n",
    "<i> Balázs Kégl (LAL/CNRS), Alex Gramfort (Inria), Djalel Benbouzid (UPMC), Mehdi Cherti (LAL/CNRS) </i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "The data set was donated to us by an unnamed company handling flight ticket reservations. The data is thin, it contains\n",
    "<ul>\n",
    "<li> the date of departure\n",
    "<li> the departure airport\n",
    "<li> the arrival airport\n",
    "<li> the mean and standard deviation of the number of weeks of the reservations made before the departure date\n",
    "<li> a field called <code>log_PAX</code> which is related to the number of passengers (the actual number were changed for privacy reasons)\n",
    "</ul>\n",
    "\n",
    "The goal is to predict the <code>log_PAX</code> column. The prediction quality is measured by RMSE. \n",
    "\n",
    "The data is obviously limited, but since data and location informations are available, it can be joined to external data sets. <b>The challenge in this RAMP is to find good data that can be correlated to flight traffic</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset using pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training and testing data are located in the folder `data`. They are compressed `csv` file (i.e. `csv.bz2`). We can load the dataset using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    os.path.join('data', 'train.csv.bz2')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8902 entries, 0 to 8901\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   DateOfDeparture   8902 non-null   object \n",
      " 1   Departure         8902 non-null   object \n",
      " 2   Arrival           8902 non-null   object \n",
      " 3   WeeksToDeparture  8902 non-null   float64\n",
      " 4   log_PAX           8902 non-null   float64\n",
      " 5   std_wtd           8902 non-null   float64\n",
      "dtypes: float64(3), object(3)\n",
      "memory usage: 417.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateOfDeparture</th>\n",
       "      <th>Departure</th>\n",
       "      <th>Arrival</th>\n",
       "      <th>WeeksToDeparture</th>\n",
       "      <th>log_PAX</th>\n",
       "      <th>std_wtd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-06-19</td>\n",
       "      <td>ORD</td>\n",
       "      <td>DFW</td>\n",
       "      <td>12.875000</td>\n",
       "      <td>12.331296</td>\n",
       "      <td>9.812647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>LAS</td>\n",
       "      <td>DEN</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>10.775182</td>\n",
       "      <td>9.466734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-05</td>\n",
       "      <td>DEN</td>\n",
       "      <td>LAX</td>\n",
       "      <td>10.863636</td>\n",
       "      <td>11.083177</td>\n",
       "      <td>9.035883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-10-09</td>\n",
       "      <td>ATL</td>\n",
       "      <td>ORD</td>\n",
       "      <td>11.480000</td>\n",
       "      <td>11.169268</td>\n",
       "      <td>7.990202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-02-21</td>\n",
       "      <td>DEN</td>\n",
       "      <td>SFO</td>\n",
       "      <td>11.450000</td>\n",
       "      <td>11.269364</td>\n",
       "      <td>9.517159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DateOfDeparture Departure Arrival  WeeksToDeparture    log_PAX   std_wtd\n",
       "0      2012-06-19       ORD     DFW         12.875000  12.331296  9.812647\n",
       "1      2012-09-10       LAS     DEN         14.285714  10.775182  9.466734\n",
       "2      2012-10-05       DEN     LAX         10.863636  11.083177  9.035883\n",
       "3      2011-10-09       ATL     ORD         11.480000  11.169268  7.990202\n",
       "4      2012-02-21       DEN     SFO         11.450000  11.269364  9.517159"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it makes `Departure` and `Arrival` are the code of the airport, we see that the `DateOfDeparture` should be a date instead of string. We can use pandas to convert this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:, 'DateOfDeparture'] = pd.to_datetime(data.loc[:, 'DateOfDeparture'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8902 entries, 0 to 8901\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   DateOfDeparture   8902 non-null   datetime64[ns]\n",
      " 1   Departure         8902 non-null   object        \n",
      " 2   Arrival           8902 non-null   object        \n",
      " 3   WeeksToDeparture  8902 non-null   float64       \n",
      " 4   log_PAX           8902 non-null   float64       \n",
      " 5   std_wtd           8902 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(3), object(2)\n",
      "memory usage: 417.4+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you will create a submission, `ramp-workflow` will load the data for you and split into a data matrix `X` and a target vector `y`. It will also take care about splitting the data into a training and testing set. These utilities are available in the module `problem.py` which we will load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `get_train_data()` loads the training data and returns a pandas dataframe `X` and a numpy vector `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = problem.get_train_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the information of the data `X`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8902 entries, 0 to 8901\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   DateOfDeparture   8902 non-null   object \n",
      " 1   Departure         8902 non-null   object \n",
      " 2   Arrival           8902 non-null   object \n",
      " 3   WeeksToDeparture  8902 non-null   float64\n",
      " 4   std_wtd           8902 non-null   float64\n",
      "dtypes: float64(2), object(3)\n",
      "memory usage: 347.9+ KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8902, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting dates into numerical columns is a common operation when time series data is analyzed with non-parametric predictors. The code below makes the following transformations:\n",
    "\n",
    "- numerical columns for year (2011-2012), month (1-12), day of the month (1-31), day of the week (0-6), and week of the year (1-52)\n",
    "- number of days since 1970-01-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the original data to avoid writing on the original data\n",
    "X_encoded = X.copy()\n",
    "\n",
    "# following http://stackoverflow.com/questions/16453644/regression-with-date-variable-using-scikit-learn\n",
    "X_encoded['DateOfDeparture'] = pd.to_datetime(X_encoded['DateOfDeparture'])\n",
    "X_encoded['year'] = X_encoded['DateOfDeparture'].dt.year\n",
    "X_encoded['month'] = X_encoded['DateOfDeparture'].dt.month\n",
    "X_encoded['day'] = X_encoded['DateOfDeparture'].dt.day\n",
    "X_encoded['weekday'] = X_encoded['DateOfDeparture'].dt.weekday\n",
    "X_encoded['week'] = X_encoded['DateOfDeparture'].dt.week\n",
    "X_encoded['n_days'] = X_encoded['DateOfDeparture'].apply(lambda date: (date - pd.to_datetime(\"1970-01-01\")).days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateOfDeparture</th>\n",
       "      <th>Departure</th>\n",
       "      <th>Arrival</th>\n",
       "      <th>WeeksToDeparture</th>\n",
       "      <th>std_wtd</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>week</th>\n",
       "      <th>n_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8897</th>\n",
       "      <td>2011-10-02</td>\n",
       "      <td>DTW</td>\n",
       "      <td>ATL</td>\n",
       "      <td>9.263158</td>\n",
       "      <td>7.316967</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>39</td>\n",
       "      <td>15249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8898</th>\n",
       "      <td>2012-09-25</td>\n",
       "      <td>DFW</td>\n",
       "      <td>ORD</td>\n",
       "      <td>12.772727</td>\n",
       "      <td>10.641034</td>\n",
       "      <td>2012</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>15608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8899</th>\n",
       "      <td>2012-01-19</td>\n",
       "      <td>SFO</td>\n",
       "      <td>LAS</td>\n",
       "      <td>11.047619</td>\n",
       "      <td>7.908705</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>15358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8900</th>\n",
       "      <td>2013-02-03</td>\n",
       "      <td>ORD</td>\n",
       "      <td>PHL</td>\n",
       "      <td>6.076923</td>\n",
       "      <td>4.030334</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>15739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8901</th>\n",
       "      <td>2011-11-26</td>\n",
       "      <td>DTW</td>\n",
       "      <td>ATL</td>\n",
       "      <td>9.526316</td>\n",
       "      <td>6.167733</td>\n",
       "      <td>2011</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>47</td>\n",
       "      <td>15304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     DateOfDeparture Departure Arrival  WeeksToDeparture    std_wtd  year  \\\n",
       "8897      2011-10-02       DTW     ATL          9.263158   7.316967  2011   \n",
       "8898      2012-09-25       DFW     ORD         12.772727  10.641034  2012   \n",
       "8899      2012-01-19       SFO     LAS         11.047619   7.908705  2012   \n",
       "8900      2013-02-03       ORD     PHL          6.076923   4.030334  2013   \n",
       "8901      2011-11-26       DTW     ATL          9.526316   6.167733  2011   \n",
       "\n",
       "      month  day  weekday  week  n_days  \n",
       "8897     10    2        6    39   15249  \n",
       "8898      9   25        1    39   15608  \n",
       "8899      1   19        3     3   15358  \n",
       "8900      2    3        6     5   15739  \n",
       "8901     11   26        5    47   15304  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_encoded.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform all preprocessing steps within a scikit-learn [pipeline](https://scikit-learn.org/stable/modules/compose.html) which chains together tranformation and estimator steps. This offers offers convenience and safety (help avoid leaking statistics from your test data into the trained model in cross-validation) and the whole pipeline can be evaluated with `cross_val_score`.\n",
    "\n",
    "To perform the above encoding within a scikit-learn [pipeline](https://scikit-learn.org/stable/modules/compose.html) we will a function and using `FunctionTransformer` to make it compatible with scikit-learn API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "def _encode_dates(X):\n",
    "    # With pandas < 1.0, we wil get a SettingWithCopyWarning\n",
    "    # In our case, we will avoid this warning by triggering a copy\n",
    "    # More information can be found at:\n",
    "    # https://github.com/scikit-learn/scikit-learn/issues/16191\n",
    "    X_encoded = X.copy()\n",
    "\n",
    "    # Make sure that DateOfDeparture is of datetime format\n",
    "    X_encoded.loc[:, 'DateOfDeparture'] = pd.to_datetime(X_encoded['DateOfDeparture'])\n",
    "    # Encode the DateOfDeparture\n",
    "    X_encoded.loc[:, 'year'] = X_encoded['DateOfDeparture'].dt.year\n",
    "    X_encoded.loc[:, 'month'] = X_encoded['DateOfDeparture'].dt.month\n",
    "    X_encoded.loc[:, 'day'] = X_encoded['DateOfDeparture'].dt.day\n",
    "    X_encoded.loc[:, 'weekday'] = X_encoded['DateOfDeparture'].dt.weekday\n",
    "    X_encoded.loc[:, 'week'] = X_encoded['DateOfDeparture'].dt.week\n",
    "    X_encoded.loc[:, 'n_days'] = X_encoded['DateOfDeparture'].apply(\n",
    "        lambda date: (date - pd.to_datetime(\"1970-01-01\")).days\n",
    "    )\n",
    "    # Once we did the encoding, we will not need DateOfDeparture\n",
    "    return X_encoded.drop(columns=[\"DateOfDeparture\"])\n",
    "\n",
    "date_encoder = FunctionTransformer(_encode_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Departure</th>\n",
       "      <th>Arrival</th>\n",
       "      <th>WeeksToDeparture</th>\n",
       "      <th>std_wtd</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>week</th>\n",
       "      <th>n_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ORD</td>\n",
       "      <td>DFW</td>\n",
       "      <td>12.875000</td>\n",
       "      <td>9.812647</td>\n",
       "      <td>2012</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>15510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LAS</td>\n",
       "      <td>DEN</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>9.466734</td>\n",
       "      <td>2012</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>15593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DEN</td>\n",
       "      <td>LAX</td>\n",
       "      <td>10.863636</td>\n",
       "      <td>9.035883</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>15618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATL</td>\n",
       "      <td>ORD</td>\n",
       "      <td>11.480000</td>\n",
       "      <td>7.990202</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>15256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DEN</td>\n",
       "      <td>SFO</td>\n",
       "      <td>11.450000</td>\n",
       "      <td>9.517159</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>15391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Departure Arrival  WeeksToDeparture   std_wtd  year  month  day  weekday  \\\n",
       "0       ORD     DFW         12.875000  9.812647  2012      6   19        1   \n",
       "1       LAS     DEN         14.285714  9.466734  2012      9   10        0   \n",
       "2       DEN     LAX         10.863636  9.035883  2012     10    5        4   \n",
       "3       ATL     ORD         11.480000  7.990202  2011     10    9        6   \n",
       "4       DEN     SFO         11.450000  9.517159  2012      2   21        1   \n",
       "\n",
       "   week  n_days  \n",
       "0    25   15510  \n",
       "1    37   15593  \n",
       "2    40   15618  \n",
       "3    40   15256  \n",
       "4     8   15391  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_encoder.fit_transform(X).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regressor\n",
    "\n",
    "When dealing with a linear model, we need to one-hot encode categorical variables instead of ordinal encoding and standardize numerical variables. Thus we will:\n",
    "\n",
    "- encode the date;\n",
    "- then, one-hot encode all categorical columns, including the encoded date as well;\n",
    "- standardize the numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "date_encoder = FunctionTransformer(_encode_dates)\n",
    "date_cols = [\"DateOfDeparture\"]\n",
    "\n",
    "categorical_encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "categorical_cols = [\n",
    "    \"Arrival\", \"Departure\", \"year\", \"month\", \"day\",\n",
    "    \"weekday\", \"week\", \"n_days\"\n",
    "]\n",
    "\n",
    "numerical_scaler = StandardScaler()\n",
    "numerical_cols = [\"WeeksToDeparture\", \"std_wtd\"]\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (categorical_encoder, categorical_cols),\n",
    "    (numerical_scaler, numerical_cols)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now combine our `preprocessor` with the `LinearRegression` estimator in a `Pipeline`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regressor = LinearRegression()\n",
    "\n",
    "pipeline = make_pipeline(date_encoder, preprocessor, regressor) \n",
    "#first the date data is split, then onehotencoded and scaled, and then the regression is applied\n",
    "pipeline.fit(X,y)\n",
    "y_pred = pipeline.predict(X_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can evaluate our linear-model pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.6117 +/- 0.0149\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(\n",
    "    pipeline, X, y, cv=5, scoring='neg_mean_squared_error'\n",
    ")\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "print(\n",
    "    f\"RMSE: {np.mean(rmse_scores):.4f} +/- {np.std(rmse_scores):.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tests Martha**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensembles are constructed from decision tree models. Trees are added one at a time to the ensemble and fit to correct the prediction errors made by prior models. This is a type of ensemble machine learning model referred to as boosting.\n",
    "Recall that decision trees are added to the model sequentially in an effort to correct and improve upon the predictions made by prior trees (more trees require lower learning rate)\n",
    "Using fewer samples introduces more variance for each tree, although it can improve the overall performance of the model.(sub_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': 2000, #number of decision trees \n",
    "          'subsample': 1,\n",
    "          'max_depth': 8,\n",
    "          'min_samples_split': 5,\n",
    "          'learning_rate': 0.01,\n",
    "          'loss': 'ls'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble \n",
    "\n",
    "regressor2 = ensemble.GradientBoostingRegressor(**params)\n",
    "\n",
    "pipeline2 = make_pipeline(date_encoder, preprocessor, regressor2)\n",
    "pipeline2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(\n",
    "    pipeline2, X, y, cv=5, scoring='neg_mean_squared_error'\n",
    ")\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "print(\n",
    "    f\"RMSE: {np.mean(rmse_scores):.4f} +/- {np.std(rmse_scores):.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "pipeline2 = make_pipeline(date_encoder, preprocessor, regressor2)\n",
    "\n",
    "space = dict()\n",
    "space['gradientboostingregressor__n_estimators'] = [10, 500, 1000, 2000]\n",
    "space['gradientboostingregressor__subsample'] = [0.5, 0.7, 1.0]\n",
    "space['gradientboostingregressor__max_depth'] = [2, 5, 8]\n",
    "space['gradientboostingregressor__learning_rate'] = [0.001, 0.01, 0.1, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = RandomizedSearchCV(pipeline2, param_distributions=space, verbose=8)\n",
    "search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame(search.cv_results_)\n",
    "#scores_df = scores.sort(columns=['rank_test_score']).reset_index(drop='index')\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space2 = dict()\n",
    "space['gradientboostingregressor__min_samples_split'] = [0.1, 0.3, 0.8, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search2 = RandomizedSearchCV(pipeline2, param_distributions=space2, verbose=8)\n",
    "search2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df2 = pd.DataFrame(search2.cv_results_)\n",
    "#scores_df = scores.sort(columns=['rank_test_score']).reset_index(drop='index')\n",
    "scores_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Martha, adding data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source of airport info: https://openflights.org/data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'submissions/starting_kit/airport_geolocation.csv'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# when submitting a kit, the `__file__` variable will corresponds to the\n",
    "# path to `estimator.py`. However, this variable is not defined in the\n",
    "# notebook and thus we must define the `__file__` variable to imitate\n",
    "# how a submission `.py` would work.\n",
    "__file__ = os.path.join('submissions', 'starting_kit', 'estimator.py')\n",
    "filepath = os.path.join(os.path.dirname(__file__), 'airport_geolocation.csv')\n",
    "filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airport ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>IATA</th>\n",
       "      <th>ICAO</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Altitude</th>\n",
       "      <th>Timezone</th>\n",
       "      <th>DST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3411</td>\n",
       "      <td>Barter Island LRRS Airport</td>\n",
       "      <td>Barter Island</td>\n",
       "      <td>United States</td>\n",
       "      <td>BTI</td>\n",
       "      <td>PABA</td>\n",
       "      <td>70.134003</td>\n",
       "      <td>-143.582001</td>\n",
       "      <td>2</td>\n",
       "      <td>-9</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3412</td>\n",
       "      <td>Wainwright Air Station</td>\n",
       "      <td>Fort Wainwright</td>\n",
       "      <td>United States</td>\n",
       "      <td>\\N</td>\n",
       "      <td>PAWT</td>\n",
       "      <td>70.613403</td>\n",
       "      <td>-159.860001</td>\n",
       "      <td>35</td>\n",
       "      <td>-9</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3413</td>\n",
       "      <td>Cape Lisburne LRRS Airport</td>\n",
       "      <td>Cape Lisburne</td>\n",
       "      <td>United States</td>\n",
       "      <td>LUR</td>\n",
       "      <td>PALU</td>\n",
       "      <td>68.875099</td>\n",
       "      <td>-166.110001</td>\n",
       "      <td>16</td>\n",
       "      <td>-9</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3414</td>\n",
       "      <td>Point Lay LRRS Airport</td>\n",
       "      <td>Point Lay</td>\n",
       "      <td>United States</td>\n",
       "      <td>PIZ</td>\n",
       "      <td>PPIZ</td>\n",
       "      <td>69.732903</td>\n",
       "      <td>-163.005005</td>\n",
       "      <td>22</td>\n",
       "      <td>-9</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3415</td>\n",
       "      <td>Hilo International Airport</td>\n",
       "      <td>Hilo</td>\n",
       "      <td>United States</td>\n",
       "      <td>ITO</td>\n",
       "      <td>PHTO</td>\n",
       "      <td>19.721399</td>\n",
       "      <td>-155.048004</td>\n",
       "      <td>38</td>\n",
       "      <td>-10</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Airport ID                        Name             City        Country  \\\n",
       "0        3411  Barter Island LRRS Airport    Barter Island  United States   \n",
       "1        3412      Wainwright Air Station  Fort Wainwright  United States   \n",
       "2        3413  Cape Lisburne LRRS Airport    Cape Lisburne  United States   \n",
       "3        3414      Point Lay LRRS Airport        Point Lay  United States   \n",
       "4        3415  Hilo International Airport             Hilo  United States   \n",
       "\n",
       "  IATA  ICAO   Latitude   Longitude  Altitude Timezone DST  \n",
       "0  BTI  PABA  70.134003 -143.582001         2       -9   A  \n",
       "1   \\N  PAWT  70.613403 -159.860001        35       -9   A  \n",
       "2  LUR  PALU  68.875099 -166.110001        16       -9   A  \n",
       "3  PIZ  PPIZ  69.732903 -163.005005        22       -9   A  \n",
       "4  ITO  PHTO  19.721399 -155.048004        38      -10   N  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('airport_geolocation.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _merge_external_data(X):\n",
    "    X = X.copy()  # to avoid raising SettingOnCopyWarning\n",
    "    # Make sure that DateOfDeparture is of dtype datetime\n",
    "    X.loc[:, \"DateOfDeparture\"] = pd.to_datetime(X['DateOfDeparture'])\n",
    "    data_geolocation = pd.read_csv('airport_geolocation.csv')\n",
    "    data_geolocation = data_geolocation[['IATA', 'Latitude', 'Longitude']]\n",
    "    data_geolocation = data_geolocation.rename(columns={'IATA': 'Departure', 'Latitude': 'Latitude', 'Longitude': 'Longitude'})\n",
    "    X_merged = pd.merge(\n",
    "        X, data_geolocation, how='left', on=['Departure'], sort=False\n",
    "    )\n",
    "    return X_merged\n",
    "\n",
    "data_merger = FunctionTransformer(_merge_external_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateOfDeparture</th>\n",
       "      <th>Departure</th>\n",
       "      <th>Arrival</th>\n",
       "      <th>WeeksToDeparture</th>\n",
       "      <th>std_wtd</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-06-19</td>\n",
       "      <td>ORD</td>\n",
       "      <td>DFW</td>\n",
       "      <td>12.875000</td>\n",
       "      <td>9.812647</td>\n",
       "      <td>41.978600</td>\n",
       "      <td>-87.904800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>LAS</td>\n",
       "      <td>DEN</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>9.466734</td>\n",
       "      <td>36.080101</td>\n",
       "      <td>-115.152000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-05</td>\n",
       "      <td>DEN</td>\n",
       "      <td>LAX</td>\n",
       "      <td>10.863636</td>\n",
       "      <td>9.035883</td>\n",
       "      <td>39.861698</td>\n",
       "      <td>-104.672996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-10-09</td>\n",
       "      <td>ATL</td>\n",
       "      <td>ORD</td>\n",
       "      <td>11.480000</td>\n",
       "      <td>7.990202</td>\n",
       "      <td>33.636700</td>\n",
       "      <td>-84.428101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-02-21</td>\n",
       "      <td>DEN</td>\n",
       "      <td>SFO</td>\n",
       "      <td>11.450000</td>\n",
       "      <td>9.517159</td>\n",
       "      <td>39.861698</td>\n",
       "      <td>-104.672996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8897</th>\n",
       "      <td>2011-10-02</td>\n",
       "      <td>DTW</td>\n",
       "      <td>ATL</td>\n",
       "      <td>9.263158</td>\n",
       "      <td>7.316967</td>\n",
       "      <td>42.212399</td>\n",
       "      <td>-83.353401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8898</th>\n",
       "      <td>2012-09-25</td>\n",
       "      <td>DFW</td>\n",
       "      <td>ORD</td>\n",
       "      <td>12.772727</td>\n",
       "      <td>10.641034</td>\n",
       "      <td>32.896801</td>\n",
       "      <td>-97.038002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8899</th>\n",
       "      <td>2012-01-19</td>\n",
       "      <td>SFO</td>\n",
       "      <td>LAS</td>\n",
       "      <td>11.047619</td>\n",
       "      <td>7.908705</td>\n",
       "      <td>37.618999</td>\n",
       "      <td>-122.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8900</th>\n",
       "      <td>2013-02-03</td>\n",
       "      <td>ORD</td>\n",
       "      <td>PHL</td>\n",
       "      <td>6.076923</td>\n",
       "      <td>4.030334</td>\n",
       "      <td>41.978600</td>\n",
       "      <td>-87.904800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8901</th>\n",
       "      <td>2011-11-26</td>\n",
       "      <td>DTW</td>\n",
       "      <td>ATL</td>\n",
       "      <td>9.526316</td>\n",
       "      <td>6.167733</td>\n",
       "      <td>42.212399</td>\n",
       "      <td>-83.353401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8902 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DateOfDeparture Departure Arrival  WeeksToDeparture    std_wtd  \\\n",
       "0         2012-06-19       ORD     DFW         12.875000   9.812647   \n",
       "1         2012-09-10       LAS     DEN         14.285714   9.466734   \n",
       "2         2012-10-05       DEN     LAX         10.863636   9.035883   \n",
       "3         2011-10-09       ATL     ORD         11.480000   7.990202   \n",
       "4         2012-02-21       DEN     SFO         11.450000   9.517159   \n",
       "...              ...       ...     ...               ...        ...   \n",
       "8897      2011-10-02       DTW     ATL          9.263158   7.316967   \n",
       "8898      2012-09-25       DFW     ORD         12.772727  10.641034   \n",
       "8899      2012-01-19       SFO     LAS         11.047619   7.908705   \n",
       "8900      2013-02-03       ORD     PHL          6.076923   4.030334   \n",
       "8901      2011-11-26       DTW     ATL          9.526316   6.167733   \n",
       "\n",
       "       Latitude   Longitude  \n",
       "0     41.978600  -87.904800  \n",
       "1     36.080101 -115.152000  \n",
       "2     39.861698 -104.672996  \n",
       "3     33.636700  -84.428101  \n",
       "4     39.861698 -104.672996  \n",
       "...         ...         ...  \n",
       "8897  42.212399  -83.353401  \n",
       "8898  32.896801  -97.038002  \n",
       "8899  37.618999 -122.375000  \n",
       "8900  41.978600  -87.904800  \n",
       "8901  42.212399  -83.353401  \n",
       "\n",
       "[8902 rows x 7 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_merger.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'regressor2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/Desktop/Python_Labs/air_passengers_py4ds2020/submissions/starting_kit/estimator.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipeline3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_merger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregressor2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'regressor2' is not defined"
     ]
    }
   ],
   "source": [
    "pipeline3 = make_pipeline(data_merger, date_encoder, preprocessor, regressor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(\n",
    "    pipeline3, X, y, cv=5, scoring='neg_mean_squared_error'\n",
    ")\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "print(\n",
    "    f\"RMSE: {np.mean(rmse_scores):.4f} +/- {np.std(rmse_scores):.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XG Boost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8902, 12)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_nicolas = pd.read_csv('testemoica.csv')\n",
    "dat_nicolas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateOfDeparture</th>\n",
       "      <th>Departure</th>\n",
       "      <th>Arrival</th>\n",
       "      <th>WeeksToDeparture</th>\n",
       "      <th>std_wtd_x</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>week</th>\n",
       "      <th>n_days</th>\n",
       "      <th>passsengers_load</th>\n",
       "      <th>distance_km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-06-19</td>\n",
       "      <td>ORD</td>\n",
       "      <td>DFW</td>\n",
       "      <td>12.875000</td>\n",
       "      <td>9.812647</td>\n",
       "      <td>2012</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>15510</td>\n",
       "      <td>32171795.0</td>\n",
       "      <td>1290.179371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>LAS</td>\n",
       "      <td>DEN</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>9.466734</td>\n",
       "      <td>2012</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>15593</td>\n",
       "      <td>19959651.0</td>\n",
       "      <td>991.064058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-05</td>\n",
       "      <td>DEN</td>\n",
       "      <td>LAX</td>\n",
       "      <td>10.863636</td>\n",
       "      <td>9.035883</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>15618</td>\n",
       "      <td>25799841.0</td>\n",
       "      <td>1366.918847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-10-09</td>\n",
       "      <td>ATL</td>\n",
       "      <td>ORD</td>\n",
       "      <td>11.480000</td>\n",
       "      <td>7.990202</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>15256</td>\n",
       "      <td>44414121.0</td>\n",
       "      <td>974.522557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-02-21</td>\n",
       "      <td>DEN</td>\n",
       "      <td>SFO</td>\n",
       "      <td>11.450000</td>\n",
       "      <td>9.517159</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>15391</td>\n",
       "      <td>25799841.0</td>\n",
       "      <td>1538.142783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DateOfDeparture Departure Arrival  WeeksToDeparture  std_wtd_x  year  month  \\\n",
       "0      2012-06-19       ORD     DFW         12.875000   9.812647  2012      6   \n",
       "1      2012-09-10       LAS     DEN         14.285714   9.466734  2012      9   \n",
       "2      2012-10-05       DEN     LAX         10.863636   9.035883  2012     10   \n",
       "3      2011-10-09       ATL     ORD         11.480000   7.990202  2011     10   \n",
       "4      2012-02-21       DEN     SFO         11.450000   9.517159  2012      2   \n",
       "\n",
       "   day  weekday  week  n_days  passsengers_load  distance_km  \n",
       "0   19        1    25   15510        32171795.0  1290.179371  \n",
       "1   10        0    37   15593        19959651.0   991.064058  \n",
       "2    5        4    40   15618        25799841.0  1366.918847  \n",
       "3    9        6    40   15256        44414121.0   974.522557  \n",
       "4   21        1     8   15391        25799841.0  1538.142783  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _merge_external_data_N(X):\n",
    "    X = X.copy()  # to avoid raising SettingOnCopyWarning\n",
    "    # Make sure that DateOfDeparture is of dtype datetime\n",
    "    X.loc[:, \"DateOfDeparture\"] = pd.to_datetime(X['DateOfDeparture'])\n",
    "    data_nicolas = pd.read_csv('testemoica.csv')\n",
    "    data_nicolas = data_nicolas[['Departure', 'Arrival', 'WeeksToDeparture', 'std_wtd', 'year', 'month', 'day', 'weekday', 'week', 'n_days', 'passengers load', 'distance km']]\n",
    "    X_merged = pd.merge(\n",
    "        X, data_nicolas, how='left', left_index=True, right_index=True #on=[['Departure', 'Arrival', 'year', 'month', 'day']], sort=False\n",
    "    )\n",
    "    X_merged = X_merged[['DateOfDeparture', 'Departure_x', 'Arrival_x', 'WeeksToDeparture_x', 'std_wtd_x', 'year', 'month', 'day', 'weekday', 'week', 'n_days', 'passengers load', 'distance km']]\n",
    "    X_merged = X_merged.rename(\n",
    "             columns={'DateOfDeparture':'DateOfDeparture', 'Departure_x':'Departure', 'Arrival_x':'Arrival', 'WeeksToDeparture_x':'WeeksToDeparture', 'std_wtd_x':'std_wtd_x', 'year':'year', 'month':'month', 'day':'day', 'weekday':'weekday', 'week':'week', 'n_days':'n_days', 'passengers load':'passsengers_load', 'distance km':'distance_km'}\n",
    "              )\n",
    "    return X_merged\n",
    "\n",
    "data_merger_N = FunctionTransformer(_merge_external_data_N)\n",
    "data_merger_N.fit_transform(X).head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "date_encoder = FunctionTransformer(_encode_dates)\n",
    "date_cols = [\"DateOfDeparture\"]\n",
    "\n",
    "categorical_encoder = OrdinalEncoder()\n",
    "categorical_cols = [\"Arrival\", \"Departure\"]\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (date_encoder, date_cols),\n",
    "    (categorical_encoder, categorical_cols),\n",
    "    remainder='passthrough',  # passthrough numerical columns as they are\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:24:22] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:24:26] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('functiontransformer',\n",
       "                 FunctionTransformer(func=<function _merge_external_data_N at 0x7fa780a06af0>)),\n",
       "                ('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('functiontransformer',\n",
       "                                                  FunctionTransformer(func=<function _encode_dates at 0x7fa77d2e5ca0>),\n",
       "                                                  ['DateOfDeparture']),\n",
       "                                                 ('ordinalencoder',\n",
       "                                                  OrdinalEncoder(),\n",
       "                                                  ['Arrival', 'D...\n",
       "                              interaction_constraints='',\n",
       "                              learning_rate=0.300000012, max_delta_step=0,\n",
       "                              max_depth=8, min_child_weight=1, missing=nan,\n",
       "                              monotone_constraints='()', n_estimators=1000,\n",
       "                              n_jobs=0, num_parallel_tree=1,\n",
       "                              objective='reg:linear', random_state=123,\n",
       "                              reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                              seed=123, subsample=1, tree_method='exact',\n",
       "                              validate_parameters=1, verbosity=None))])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xgb_r = xgb.XGBRegressor(objective ='reg:linear', \n",
    "                  n_estimators = 1000, seed = 123, max_depth = 8)\n",
    "pipeline4 = make_pipeline(data_merger_N, preprocessor, xgb_r)\n",
    "pipeline4.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:24:52] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:24:54] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:24:55] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:24:57] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:24:59] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:25:01] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:25:02] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:25:05] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:25:06] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[21:25:08] WARNING: /Users/travis/build/dmlc/xgboost/src/objective/regression_obj.cu:174: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "RMSE: 0.3903 +/- 0.0225\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(\n",
    "    pipeline4, X, y, cv=5, scoring='neg_mean_squared_error'\n",
    ")\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "print(\n",
    "    f\"RMSE: {np.mean(rmse_scores):.4f} +/- {np.std(rmse_scores):.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('functiontransformer',\n",
       "                 FunctionTransformer(func=<function _merge_external_data_N at 0x7ffe806464c0>)),\n",
       "                ('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('functiontransformer',\n",
       "                                                  FunctionTransformer(func=<function _encode_dates at 0x7ffe7be18550>),\n",
       "                                                  ['DateOfDeparture']),\n",
       "                                                 ('ordinalencoder',\n",
       "                                                  OrdinalEncoder(),\n",
       "                                                  ['Arrival', 'D...\n",
       "                              colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "                              importance_type='gain',\n",
       "                              interaction_constraints='',\n",
       "                              learning_rate=0.300000012, max_delta_step=0,\n",
       "                              max_depth=4, min_child_weight=1, missing=nan,\n",
       "                              monotone_constraints='()', n_estimators=500,\n",
       "                              n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "                              reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                              subsample=1, tree_method='exact',\n",
       "                              validate_parameters=1, verbosity=None))])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xgb_r = xgb.XGBRegressor(n_estimators = 500, max_depth = 4)\n",
    "pipeline5 = make_pipeline(data_merger_N, preprocessor, xgb_r)\n",
    "pipeline5.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.3816 +/- 0.0224\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(\n",
    "    pipeline5, X, y, cv=5, scoring='neg_mean_squared_error'\n",
    ")\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "print(\n",
    "    f\"RMSE: {np.mean(rmse_scores):.4f} +/- {np.std(rmse_scores):.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_xgb = {'n_estimators': 2000, #number of decision trees \n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_xgb = dict()\n",
    "space_xgb['xgbregressor__n_estimators'] = [500, 1000, 2000, 5000]\n",
    "space_xgb['xgbregressor__max_depth'] = [2, 4, 6, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] xgbregressor__n_estimators=1000, xgbregressor__max_depth=2 ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  xgbregressor__n_estimators=1000, xgbregressor__max_depth=2, score=0.834, total=   2.2s\n",
      "[CV] xgbregressor__n_estimators=1000, xgbregressor__max_depth=2 ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  xgbregressor__n_estimators=1000, xgbregressor__max_depth=2, score=0.838, total=   2.1s\n",
      "[CV] xgbregressor__n_estimators=1000, xgbregressor__max_depth=2 ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  xgbregressor__n_estimators=1000, xgbregressor__max_depth=2, score=0.833, total=   2.1s\n",
      "[CV] xgbregressor__n_estimators=1000, xgbregressor__max_depth=2 ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    6.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  xgbregressor__n_estimators=1000, xgbregressor__max_depth=2, score=0.813, total=   2.1s\n",
      "[CV] xgbregressor__n_estimators=1000, xgbregressor__max_depth=2 ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    8.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  xgbregressor__n_estimators=1000, xgbregressor__max_depth=2, score=0.834, total=   2.2s\n",
      "[CV] xgbregressor__n_estimators=1000, xgbregressor__max_depth=4 ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   10.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  xgbregressor__n_estimators=1000, xgbregressor__max_depth=4, score=0.856, total=   4.0s\n",
      "[CV] xgbregressor__n_estimators=1000, xgbregressor__max_depth=4 ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   14.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  xgbregressor__n_estimators=1000, xgbregressor__max_depth=4, score=0.839, total=   4.3s\n",
      "[CV] xgbregressor__n_estimators=1000, xgbregressor__max_depth=4 ......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   19.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  xgbregressor__n_estimators=1000, xgbregressor__max_depth=4, score=0.863, total=   4.4s\n",
      "[CV] xgbregressor__n_estimators=1000, xgbregressor__max_depth=4 ......\n",
      "[CV]  xgbregressor__n_estimators=1000, xgbregressor__max_depth=4, score=0.838, total=   4.1s\n",
      "[CV] xgbregressor__n_estimators=1000, xgbregressor__max_depth=4 ......\n",
      "[CV]  xgbregressor__n_estimators=1000, xgbregressor__max_depth=4, score=0.858, total=   4.2s\n",
      "[CV] xgbregressor__n_estimators=2000, xgbregressor__max_depth=8 ......\n",
      "[CV]  xgbregressor__n_estimators=2000, xgbregressor__max_depth=8, score=0.855, total=   5.5s\n",
      "[CV] xgbregressor__n_estimators=2000, xgbregressor__max_depth=8 ......\n",
      "[CV]  xgbregressor__n_estimators=2000, xgbregressor__max_depth=8, score=0.845, total=   5.1s\n",
      "[CV] xgbregressor__n_estimators=2000, xgbregressor__max_depth=8 ......\n",
      "[CV]  xgbregressor__n_estimators=2000, xgbregressor__max_depth=8, score=0.855, total=   5.1s\n",
      "[CV] xgbregressor__n_estimators=2000, xgbregressor__max_depth=8 ......\n",
      "[CV]  xgbregressor__n_estimators=2000, xgbregressor__max_depth=8, score=0.828, total=   6.0s\n",
      "[CV] xgbregressor__n_estimators=2000, xgbregressor__max_depth=8 ......\n",
      "[CV]  xgbregressor__n_estimators=2000, xgbregressor__max_depth=8, score=0.845, total=   5.7s\n",
      "[CV] xgbregressor__n_estimators=500, xgbregressor__max_depth=4 .......\n",
      "[CV]  xgbregressor__n_estimators=500, xgbregressor__max_depth=4, score=0.859, total=   2.7s\n",
      "[CV] xgbregressor__n_estimators=500, xgbregressor__max_depth=4 .......\n",
      "[CV]  xgbregressor__n_estimators=500, xgbregressor__max_depth=4, score=0.842, total=   2.8s\n",
      "[CV] xgbregressor__n_estimators=500, xgbregressor__max_depth=4 .......\n",
      "[CV]  xgbregressor__n_estimators=500, xgbregressor__max_depth=4, score=0.864, total=   2.8s\n",
      "[CV] xgbregressor__n_estimators=500, xgbregressor__max_depth=4 .......\n",
      "[CV]  xgbregressor__n_estimators=500, xgbregressor__max_depth=4, score=0.838, total=   2.8s\n",
      "[CV] xgbregressor__n_estimators=500, xgbregressor__max_depth=4 .......\n",
      "[CV]  xgbregressor__n_estimators=500, xgbregressor__max_depth=4, score=0.860, total=   3.3s\n",
      "[CV] xgbregressor__n_estimators=500, xgbregressor__max_depth=2 .......\n",
      "[CV]  xgbregressor__n_estimators=500, xgbregressor__max_depth=2, score=0.827, total=   2.0s\n",
      "[CV] xgbregressor__n_estimators=500, xgbregressor__max_depth=2 .......\n",
      "[CV]  xgbregressor__n_estimators=500, xgbregressor__max_depth=2, score=0.821, total=   2.2s\n",
      "[CV] xgbregressor__n_estimators=500, xgbregressor__max_depth=2 .......\n",
      "[CV]  xgbregressor__n_estimators=500, xgbregressor__max_depth=2, score=0.826, total=   2.5s\n",
      "[CV] xgbregressor__n_estimators=500, xgbregressor__max_depth=2 .......\n",
      "[CV]  xgbregressor__n_estimators=500, xgbregressor__max_depth=2, score=0.804, total=   2.0s\n",
      "[CV] xgbregressor__n_estimators=500, xgbregressor__max_depth=2 .......\n",
      "[CV]  xgbregressor__n_estimators=500, xgbregressor__max_depth=2, score=0.827, total=   2.2s\n",
      "[CV] xgbregressor__n_estimators=500, xgbregressor__max_depth=6 .......\n",
      "[CV]  xgbregressor__n_estimators=500, xgbregressor__max_depth=6, score=0.866, total=   3.7s\n",
      "[CV] xgbregressor__n_estimators=500, xgbregressor__max_depth=6 .......\n",
      "[CV]  xgbregressor__n_estimators=500, xgbregressor__max_depth=6, score=0.854, total=   3.4s\n",
      "[CV] xgbregressor__n_estimators=500, xgbregressor__max_depth=6 .......\n",
      "[CV]  xgbregressor__n_estimators=500, xgbregressor__max_depth=6, score=0.858, total=   3.9s\n",
      "[CV] xgbregressor__n_estimators=500, xgbregressor__max_depth=6 .......\n",
      "[CV]  xgbregressor__n_estimators=500, xgbregressor__max_depth=6, score=0.829, total=   4.4s\n",
      "[CV] xgbregressor__n_estimators=500, xgbregressor__max_depth=6 .......\n",
      "[CV]  xgbregressor__n_estimators=500, xgbregressor__max_depth=6, score=0.849, total=   4.9s\n",
      "[CV] xgbregressor__n_estimators=5000, xgbregressor__max_depth=6 ......\n",
      "[CV]  xgbregressor__n_estimators=5000, xgbregressor__max_depth=6, score=0.866, total=  11.2s\n",
      "[CV] xgbregressor__n_estimators=5000, xgbregressor__max_depth=6 ......\n",
      "[CV]  xgbregressor__n_estimators=5000, xgbregressor__max_depth=6, score=0.854, total=  10.3s\n",
      "[CV] xgbregressor__n_estimators=5000, xgbregressor__max_depth=6 ......\n",
      "[CV]  xgbregressor__n_estimators=5000, xgbregressor__max_depth=6, score=0.858, total=   9.9s\n",
      "[CV] xgbregressor__n_estimators=5000, xgbregressor__max_depth=6 ......\n",
      "[CV]  xgbregressor__n_estimators=5000, xgbregressor__max_depth=6, score=0.829, total=  12.6s\n",
      "[CV] xgbregressor__n_estimators=5000, xgbregressor__max_depth=6 ......\n",
      "[CV]  xgbregressor__n_estimators=5000, xgbregressor__max_depth=6, score=0.849, total=  13.5s\n",
      "[CV] xgbregressor__n_estimators=2000, xgbregressor__max_depth=4 ......\n",
      "[CV]  xgbregressor__n_estimators=2000, xgbregressor__max_depth=4, score=0.853, total=   7.9s\n",
      "[CV] xgbregressor__n_estimators=2000, xgbregressor__max_depth=4 ......\n",
      "[CV]  xgbregressor__n_estimators=2000, xgbregressor__max_depth=4, score=0.835, total=   7.5s\n",
      "[CV] xgbregressor__n_estimators=2000, xgbregressor__max_depth=4 ......\n",
      "[CV]  xgbregressor__n_estimators=2000, xgbregressor__max_depth=4, score=0.861, total=   7.4s\n",
      "[CV] xgbregressor__n_estimators=2000, xgbregressor__max_depth=4 ......\n",
      "[CV]  xgbregressor__n_estimators=2000, xgbregressor__max_depth=4, score=0.838, total=   8.2s\n",
      "[CV] xgbregressor__n_estimators=2000, xgbregressor__max_depth=4 ......\n",
      "[CV]  xgbregressor__n_estimators=2000, xgbregressor__max_depth=4, score=0.855, total=  10.9s\n",
      "[CV] xgbregressor__n_estimators=5000, xgbregressor__max_depth=8 ......\n",
      "[CV]  xgbregressor__n_estimators=5000, xgbregressor__max_depth=8, score=0.855, total=  11.3s\n",
      "[CV] xgbregressor__n_estimators=5000, xgbregressor__max_depth=8 ......\n",
      "[CV]  xgbregressor__n_estimators=5000, xgbregressor__max_depth=8, score=0.845, total=   9.3s\n",
      "[CV] xgbregressor__n_estimators=5000, xgbregressor__max_depth=8 ......\n",
      "[CV]  xgbregressor__n_estimators=5000, xgbregressor__max_depth=8, score=0.855, total=  10.5s\n",
      "[CV] xgbregressor__n_estimators=5000, xgbregressor__max_depth=8 ......\n",
      "[CV]  xgbregressor__n_estimators=5000, xgbregressor__max_depth=8, score=0.828, total=   9.6s\n",
      "[CV] xgbregressor__n_estimators=5000, xgbregressor__max_depth=8 ......\n",
      "[CV]  xgbregressor__n_estimators=5000, xgbregressor__max_depth=8, score=0.845, total=   8.9s\n",
      "[CV] xgbregressor__n_estimators=1000, xgbregressor__max_depth=6 ......\n",
      "[CV]  xgbregressor__n_estimators=1000, xgbregressor__max_depth=6, score=0.866, total=   7.2s\n",
      "[CV] xgbregressor__n_estimators=1000, xgbregressor__max_depth=6 ......\n",
      "[CV]  xgbregressor__n_estimators=1000, xgbregressor__max_depth=6, score=0.854, total=   6.7s\n",
      "[CV] xgbregressor__n_estimators=1000, xgbregressor__max_depth=6 ......\n",
      "[CV]  xgbregressor__n_estimators=1000, xgbregressor__max_depth=6, score=0.858, total=   6.0s\n",
      "[CV] xgbregressor__n_estimators=1000, xgbregressor__max_depth=6 ......\n",
      "[CV]  xgbregressor__n_estimators=1000, xgbregressor__max_depth=6, score=0.829, total=   6.9s\n",
      "[CV] xgbregressor__n_estimators=1000, xgbregressor__max_depth=6 ......\n",
      "[CV]  xgbregressor__n_estimators=1000, xgbregressor__max_depth=6, score=0.849, total=   7.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  4.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=Pipeline(steps=[('functiontransformer',\n",
       "                                              FunctionTransformer(func=<function _merge_external_data_N at 0x7ffe806464c0>)),\n",
       "                                             ('columntransformer',\n",
       "                                              ColumnTransformer(remainder='passthrough',\n",
       "                                                                transformers=[('functiontransformer',\n",
       "                                                                               FunctionTransformer(func=<function _encode_dates at 0x7ffe7be18550>),\n",
       "                                                                               ['DateOfDeparture']),\n",
       "                                                                              ('ordinalencoder',\n",
       "                                                                               O...\n",
       "                                                           min_child_weight=1,\n",
       "                                                           missing=nan,\n",
       "                                                           monotone_constraints='()',\n",
       "                                                           n_estimators=2000,\n",
       "                                                           n_jobs=0,\n",
       "                                                           num_parallel_tree=1,\n",
       "                                                           random_state=0,\n",
       "                                                           reg_alpha=0,\n",
       "                                                           reg_lambda=1,\n",
       "                                                           scale_pos_weight=1,\n",
       "                                                           subsample=1,\n",
       "                                                           tree_method='exact',\n",
       "                                                           validate_parameters=1,\n",
       "                                                           verbosity=None))]),\n",
       "                   param_distributions={'xgbregressor__max_depth': [2, 4, 6, 8],\n",
       "                                        'xgbregressor__n_estimators': [500,\n",
       "                                                                       1000,\n",
       "                                                                       2000,\n",
       "                                                                       5000]},\n",
       "                   verbose=8)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = RandomizedSearchCV(pipeline5, param_distributions=space_xgb, verbose=8)\n",
    "search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_xgbregressor__n_estimators</th>\n",
       "      <th>param_xgbregressor__max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.894366</td>\n",
       "      <td>0.018658</td>\n",
       "      <td>0.261792</td>\n",
       "      <td>0.015491</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>{'xgbregressor__n_estimators': 1000, 'xgbregre...</td>\n",
       "      <td>0.834215</td>\n",
       "      <td>0.838110</td>\n",
       "      <td>0.833492</td>\n",
       "      <td>0.812999</td>\n",
       "      <td>0.833544</td>\n",
       "      <td>0.830472</td>\n",
       "      <td>0.008902</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.875738</td>\n",
       "      <td>0.134038</td>\n",
       "      <td>0.297964</td>\n",
       "      <td>0.019988</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>{'xgbregressor__n_estimators': 1000, 'xgbregre...</td>\n",
       "      <td>0.856041</td>\n",
       "      <td>0.838577</td>\n",
       "      <td>0.863176</td>\n",
       "      <td>0.837994</td>\n",
       "      <td>0.857625</td>\n",
       "      <td>0.850683</td>\n",
       "      <td>0.010398</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.164105</td>\n",
       "      <td>0.337951</td>\n",
       "      <td>0.299661</td>\n",
       "      <td>0.010206</td>\n",
       "      <td>2000</td>\n",
       "      <td>8</td>\n",
       "      <td>{'xgbregressor__n_estimators': 2000, 'xgbregre...</td>\n",
       "      <td>0.855428</td>\n",
       "      <td>0.844949</td>\n",
       "      <td>0.854719</td>\n",
       "      <td>0.828442</td>\n",
       "      <td>0.844625</td>\n",
       "      <td>0.845633</td>\n",
       "      <td>0.009752</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.554008</td>\n",
       "      <td>0.213880</td>\n",
       "      <td>0.327158</td>\n",
       "      <td>0.008927</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>{'xgbregressor__n_estimators': 500, 'xgbregres...</td>\n",
       "      <td>0.859004</td>\n",
       "      <td>0.841616</td>\n",
       "      <td>0.863867</td>\n",
       "      <td>0.837594</td>\n",
       "      <td>0.859589</td>\n",
       "      <td>0.852334</td>\n",
       "      <td>0.010605</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.842755</td>\n",
       "      <td>0.166217</td>\n",
       "      <td>0.325981</td>\n",
       "      <td>0.011370</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>{'xgbregressor__n_estimators': 500, 'xgbregres...</td>\n",
       "      <td>0.826916</td>\n",
       "      <td>0.821482</td>\n",
       "      <td>0.825802</td>\n",
       "      <td>0.804028</td>\n",
       "      <td>0.826654</td>\n",
       "      <td>0.820976</td>\n",
       "      <td>0.008698</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.731842</td>\n",
       "      <td>0.511455</td>\n",
       "      <td>0.346164</td>\n",
       "      <td>0.032921</td>\n",
       "      <td>500</td>\n",
       "      <td>6</td>\n",
       "      <td>{'xgbregressor__n_estimators': 500, 'xgbregres...</td>\n",
       "      <td>0.866295</td>\n",
       "      <td>0.854334</td>\n",
       "      <td>0.858057</td>\n",
       "      <td>0.828751</td>\n",
       "      <td>0.849479</td>\n",
       "      <td>0.851383</td>\n",
       "      <td>0.012582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11.157346</td>\n",
       "      <td>1.348288</td>\n",
       "      <td>0.342296</td>\n",
       "      <td>0.014839</td>\n",
       "      <td>5000</td>\n",
       "      <td>6</td>\n",
       "      <td>{'xgbregressor__n_estimators': 5000, 'xgbregre...</td>\n",
       "      <td>0.865567</td>\n",
       "      <td>0.853514</td>\n",
       "      <td>0.857710</td>\n",
       "      <td>0.828576</td>\n",
       "      <td>0.849134</td>\n",
       "      <td>0.850900</td>\n",
       "      <td>0.012408</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.000274</td>\n",
       "      <td>1.283662</td>\n",
       "      <td>0.367252</td>\n",
       "      <td>0.024799</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>{'xgbregressor__n_estimators': 2000, 'xgbregre...</td>\n",
       "      <td>0.852668</td>\n",
       "      <td>0.835383</td>\n",
       "      <td>0.861434</td>\n",
       "      <td>0.837861</td>\n",
       "      <td>0.854910</td>\n",
       "      <td>0.848451</td>\n",
       "      <td>0.010109</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.543667</td>\n",
       "      <td>0.828303</td>\n",
       "      <td>0.355981</td>\n",
       "      <td>0.032957</td>\n",
       "      <td>5000</td>\n",
       "      <td>8</td>\n",
       "      <td>{'xgbregressor__n_estimators': 5000, 'xgbregre...</td>\n",
       "      <td>0.855428</td>\n",
       "      <td>0.844949</td>\n",
       "      <td>0.854719</td>\n",
       "      <td>0.828442</td>\n",
       "      <td>0.844625</td>\n",
       "      <td>0.845633</td>\n",
       "      <td>0.009752</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.493992</td>\n",
       "      <td>0.475016</td>\n",
       "      <td>0.362459</td>\n",
       "      <td>0.034016</td>\n",
       "      <td>1000</td>\n",
       "      <td>6</td>\n",
       "      <td>{'xgbregressor__n_estimators': 1000, 'xgbregre...</td>\n",
       "      <td>0.865623</td>\n",
       "      <td>0.853529</td>\n",
       "      <td>0.857731</td>\n",
       "      <td>0.828575</td>\n",
       "      <td>0.849153</td>\n",
       "      <td>0.850922</td>\n",
       "      <td>0.012424</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       1.894366      0.018658         0.261792        0.015491   \n",
       "1       3.875738      0.134038         0.297964        0.019988   \n",
       "2       5.164105      0.337951         0.299661        0.010206   \n",
       "3       2.554008      0.213880         0.327158        0.008927   \n",
       "4       1.842755      0.166217         0.325981        0.011370   \n",
       "5       3.731842      0.511455         0.346164        0.032921   \n",
       "6      11.157346      1.348288         0.342296        0.014839   \n",
       "7       8.000274      1.283662         0.367252        0.024799   \n",
       "8       9.543667      0.828303         0.355981        0.032957   \n",
       "9       6.493992      0.475016         0.362459        0.034016   \n",
       "\n",
       "  param_xgbregressor__n_estimators param_xgbregressor__max_depth  \\\n",
       "0                             1000                             2   \n",
       "1                             1000                             4   \n",
       "2                             2000                             8   \n",
       "3                              500                             4   \n",
       "4                              500                             2   \n",
       "5                              500                             6   \n",
       "6                             5000                             6   \n",
       "7                             2000                             4   \n",
       "8                             5000                             8   \n",
       "9                             1000                             6   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'xgbregressor__n_estimators': 1000, 'xgbregre...           0.834215   \n",
       "1  {'xgbregressor__n_estimators': 1000, 'xgbregre...           0.856041   \n",
       "2  {'xgbregressor__n_estimators': 2000, 'xgbregre...           0.855428   \n",
       "3  {'xgbregressor__n_estimators': 500, 'xgbregres...           0.859004   \n",
       "4  {'xgbregressor__n_estimators': 500, 'xgbregres...           0.826916   \n",
       "5  {'xgbregressor__n_estimators': 500, 'xgbregres...           0.866295   \n",
       "6  {'xgbregressor__n_estimators': 5000, 'xgbregre...           0.865567   \n",
       "7  {'xgbregressor__n_estimators': 2000, 'xgbregre...           0.852668   \n",
       "8  {'xgbregressor__n_estimators': 5000, 'xgbregre...           0.855428   \n",
       "9  {'xgbregressor__n_estimators': 1000, 'xgbregre...           0.865623   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.838110           0.833492           0.812999           0.833544   \n",
       "1           0.838577           0.863176           0.837994           0.857625   \n",
       "2           0.844949           0.854719           0.828442           0.844625   \n",
       "3           0.841616           0.863867           0.837594           0.859589   \n",
       "4           0.821482           0.825802           0.804028           0.826654   \n",
       "5           0.854334           0.858057           0.828751           0.849479   \n",
       "6           0.853514           0.857710           0.828576           0.849134   \n",
       "7           0.835383           0.861434           0.837861           0.854910   \n",
       "8           0.844949           0.854719           0.828442           0.844625   \n",
       "9           0.853529           0.857731           0.828575           0.849153   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.830472        0.008902                9  \n",
       "1         0.850683        0.010398                5  \n",
       "2         0.845633        0.009752                7  \n",
       "3         0.852334        0.010605                1  \n",
       "4         0.820976        0.008698               10  \n",
       "5         0.851383        0.012582                2  \n",
       "6         0.850900        0.012408                4  \n",
       "7         0.848451        0.010109                6  \n",
       "8         0.845633        0.009752                7  \n",
       "9         0.850922        0.012424                3  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(search.cv_results_)\n",
    "#scores_df = scores.sort(columns=['rank_test_score']).reset_index(drop='index')\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient Boost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': 2000, #number of decision trees \n",
    "          'subsample': 0.5,\n",
    "          'max_depth': 8,\n",
    "          'min_samples_split': 5,\n",
    "          'learning_rate': 0.01,\n",
    "          'loss': 'ls'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('functiontransformer',\n",
       "                 FunctionTransformer(func=<function _merge_external_data_N at 0x7ffe806464c0>)),\n",
       "                ('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('functiontransformer',\n",
       "                                                  FunctionTransformer(func=<function _encode_dates at 0x7ffe7be18550>),\n",
       "                                                  ['DateOfDeparture']),\n",
       "                                                 ('ordinalencoder',\n",
       "                                                  OrdinalEncoder(),\n",
       "                                                  ['Arrival', 'Departure'])])),\n",
       "                ('gradientboostingregressor',\n",
       "                 GradientBoostingRegressor(learning_rate=0.01, max_depth=8,\n",
       "                                           min_samples_split=5,\n",
       "                                           n_estimators=2000, subsample=0.5))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import ensemble \n",
    "\n",
    "GradBoost = ensemble.GradientBoostingRegressor(**params)\n",
    "\n",
    "pipeline6 = make_pipeline(data_merger_N, preprocessor, GradBoost)\n",
    "pipeline6.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.3605 +/- 0.0264\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(\n",
    "    pipeline6, X, y, cv=5, scoring='neg_mean_squared_error'\n",
    ")\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "print(\n",
    "    f\"RMSE: {np.mean(rmse_scores):.4f} +/- {np.std(rmse_scores):.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "space = dict()\n",
    "space['gradientboostingregressor__n_estimators'] = [500, 1000, 2000]\n",
    "space['gradientboostingregressor__subsample'] = [0.5, 0.7, 1.0]\n",
    "space['gradientboostingregressor__max_depth'] = [2, 5, 8]\n",
    "space['gradientboostingregressor__learning_rate'] = [0.001, 0.01, 0.1, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.001 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.001, score=0.619, total=  37.5s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.001 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   37.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.001, score=0.585, total=  38.0s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.001 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  1.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.001, score=0.616, total=  36.0s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.001 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  1.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.001, score=0.606, total=  36.1s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.001 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  2.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.001, score=0.620, total=  35.2s\n",
      "[CV] gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.01 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  3.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.01, score=0.881, total=  40.0s\n",
      "[CV] gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.01 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  3.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.01, score=0.863, total=  39.9s\n",
      "[CV] gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.01 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  4.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.01, score=0.875, total=  40.1s\n",
      "[CV] gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.01, score=0.850, total=  42.5s\n",
      "[CV] gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.01, score=0.877, total=  50.1s\n",
      "[CV] gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=1.0 \n",
      "[CV]  gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=1.0, score=0.630, total=  15.8s\n",
      "[CV] gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=1.0 \n",
      "[CV]  gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=1.0, score=0.698, total=  14.4s\n",
      "[CV] gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=1.0 \n",
      "[CV]  gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=1.0, score=0.686, total=  13.7s\n",
      "[CV] gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=1.0 \n",
      "[CV]  gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=1.0, score=0.624, total=  13.6s\n",
      "[CV] gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=1.0 \n",
      "[CV]  gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=1.0, score=0.677, total=  13.3s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01, score=0.783, total=   9.7s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01, score=0.761, total=   9.9s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01, score=0.778, total=   9.9s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01, score=0.764, total=   9.8s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01, score=0.785, total=   9.5s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.1 \n",
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.1, score=0.870, total=  14.5s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.1 \n",
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.1, score=0.843, total=  14.4s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.1 \n",
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.1, score=0.867, total=  14.4s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.1 \n",
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.1, score=0.839, total=  14.2s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.1 \n",
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.1, score=0.864, total=  14.2s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.1 \n",
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.1, score=0.870, total=   9.7s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.1 \n",
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.1, score=0.861, total=   9.6s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.1 \n",
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.1, score=0.870, total=   9.9s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.1 \n",
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.1, score=0.849, total=   9.6s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.1, score=0.872, total=   9.8s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=1.0 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=1.0, score=0.708, total=  12.4s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=1.0 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=1.0, score=0.674, total=  12.5s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=1.0 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=1.0, score=0.708, total=  12.6s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=1.0 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=1.0, score=0.683, total=  12.7s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=1.0 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=1.0, score=0.670, total=  12.7s\n",
      "[CV] gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=1.0 \n",
      "[CV]  gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=1.0, score=0.679, total=   3.9s\n",
      "[CV] gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=1.0 \n",
      "[CV]  gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=1.0, score=0.748, total=   4.0s\n",
      "[CV] gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=1.0 \n",
      "[CV]  gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=1.0, score=0.701, total=   4.3s\n",
      "[CV] gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=1.0 \n",
      "[CV]  gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=1.0, score=0.723, total=   4.1s\n",
      "[CV] gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=1.0 \n",
      "[CV]  gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=1.0, score=0.716, total=   4.3s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=1.0 \n",
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=1.0, score=0.322, total=  35.8s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=1.0 \n",
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=1.0, score=0.492, total=  35.4s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=1.0 \n",
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=1.0, score=0.464, total=  35.3s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=1.0 \n",
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=1.0, score=0.454, total=  35.4s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=1.0 \n",
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=1.0, score=0.455, total=  35.2s\n",
      "[CV] gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.1 \n",
      "[CV]  gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.1, score=0.861, total=  13.9s\n",
      "[CV] gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.1 \n",
      "[CV]  gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.1, score=0.859, total=  13.8s\n",
      "[CV] gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.1 \n",
      "[CV]  gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.1, score=0.868, total=  14.1s\n",
      "[CV] gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.1 \n",
      "[CV]  gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.1, score=0.840, total=  14.2s\n",
      "[CV] gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.1 \n",
      "[CV]  gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.1, score=0.867, total=  14.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed: 16.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=Pipeline(steps=[('functiontransformer',\n",
       "                                              FunctionTransformer(func=<function _merge_external_data_N at 0x7ffe806464c0>)),\n",
       "                                             ('columntransformer',\n",
       "                                              ColumnTransformer(remainder='passthrough',\n",
       "                                                                transformers=[('functiontransformer',\n",
       "                                                                               FunctionTransformer(func=<function _encode_dates at 0x7ffe7be18550>),\n",
       "                                                                               ['DateOfDeparture']),\n",
       "                                                                              ('ordinalencoder',\n",
       "                                                                               O...\n",
       "                                              GradientBoostingRegressor(learning_rate=0.01,\n",
       "                                                                        max_depth=8,\n",
       "                                                                        min_samples_split=5,\n",
       "                                                                        n_estimators=2000,\n",
       "                                                                        subsample=1))]),\n",
       "                   param_distributions={'gradientboostingregressor__learning_rate': [0.001,\n",
       "                                                                                     0.01,\n",
       "                                                                                     0.1,\n",
       "                                                                                     1.0],\n",
       "                                        'gradientboostingregressor__max_depth': [2,\n",
       "                                                                                 5,\n",
       "                                                                                 8],\n",
       "                                        'gradientboostingregressor__n_estimators': [500,\n",
       "                                                                                    1000,\n",
       "                                                                                    2000],\n",
       "                                        'gradientboostingregressor__subsample': [0.5,\n",
       "                                                                                 0.7,\n",
       "                                                                                 1.0]},\n",
       "                   verbose=8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = RandomizedSearchCV(pipeline6, param_distributions=space, verbose=8)\n",
    "search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_xgbregressor__n_estimators</th>\n",
       "      <th>param_xgbregressor__max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.894366</td>\n",
       "      <td>0.018658</td>\n",
       "      <td>0.261792</td>\n",
       "      <td>0.015491</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "      <td>{'xgbregressor__n_estimators': 1000, 'xgbregre...</td>\n",
       "      <td>0.834215</td>\n",
       "      <td>0.838110</td>\n",
       "      <td>0.833492</td>\n",
       "      <td>0.812999</td>\n",
       "      <td>0.833544</td>\n",
       "      <td>0.830472</td>\n",
       "      <td>0.008902</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.875738</td>\n",
       "      <td>0.134038</td>\n",
       "      <td>0.297964</td>\n",
       "      <td>0.019988</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "      <td>{'xgbregressor__n_estimators': 1000, 'xgbregre...</td>\n",
       "      <td>0.856041</td>\n",
       "      <td>0.838577</td>\n",
       "      <td>0.863176</td>\n",
       "      <td>0.837994</td>\n",
       "      <td>0.857625</td>\n",
       "      <td>0.850683</td>\n",
       "      <td>0.010398</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.164105</td>\n",
       "      <td>0.337951</td>\n",
       "      <td>0.299661</td>\n",
       "      <td>0.010206</td>\n",
       "      <td>2000</td>\n",
       "      <td>8</td>\n",
       "      <td>{'xgbregressor__n_estimators': 2000, 'xgbregre...</td>\n",
       "      <td>0.855428</td>\n",
       "      <td>0.844949</td>\n",
       "      <td>0.854719</td>\n",
       "      <td>0.828442</td>\n",
       "      <td>0.844625</td>\n",
       "      <td>0.845633</td>\n",
       "      <td>0.009752</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.554008</td>\n",
       "      <td>0.213880</td>\n",
       "      <td>0.327158</td>\n",
       "      <td>0.008927</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>{'xgbregressor__n_estimators': 500, 'xgbregres...</td>\n",
       "      <td>0.859004</td>\n",
       "      <td>0.841616</td>\n",
       "      <td>0.863867</td>\n",
       "      <td>0.837594</td>\n",
       "      <td>0.859589</td>\n",
       "      <td>0.852334</td>\n",
       "      <td>0.010605</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.842755</td>\n",
       "      <td>0.166217</td>\n",
       "      <td>0.325981</td>\n",
       "      <td>0.011370</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>{'xgbregressor__n_estimators': 500, 'xgbregres...</td>\n",
       "      <td>0.826916</td>\n",
       "      <td>0.821482</td>\n",
       "      <td>0.825802</td>\n",
       "      <td>0.804028</td>\n",
       "      <td>0.826654</td>\n",
       "      <td>0.820976</td>\n",
       "      <td>0.008698</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.731842</td>\n",
       "      <td>0.511455</td>\n",
       "      <td>0.346164</td>\n",
       "      <td>0.032921</td>\n",
       "      <td>500</td>\n",
       "      <td>6</td>\n",
       "      <td>{'xgbregressor__n_estimators': 500, 'xgbregres...</td>\n",
       "      <td>0.866295</td>\n",
       "      <td>0.854334</td>\n",
       "      <td>0.858057</td>\n",
       "      <td>0.828751</td>\n",
       "      <td>0.849479</td>\n",
       "      <td>0.851383</td>\n",
       "      <td>0.012582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11.157346</td>\n",
       "      <td>1.348288</td>\n",
       "      <td>0.342296</td>\n",
       "      <td>0.014839</td>\n",
       "      <td>5000</td>\n",
       "      <td>6</td>\n",
       "      <td>{'xgbregressor__n_estimators': 5000, 'xgbregre...</td>\n",
       "      <td>0.865567</td>\n",
       "      <td>0.853514</td>\n",
       "      <td>0.857710</td>\n",
       "      <td>0.828576</td>\n",
       "      <td>0.849134</td>\n",
       "      <td>0.850900</td>\n",
       "      <td>0.012408</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.000274</td>\n",
       "      <td>1.283662</td>\n",
       "      <td>0.367252</td>\n",
       "      <td>0.024799</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>{'xgbregressor__n_estimators': 2000, 'xgbregre...</td>\n",
       "      <td>0.852668</td>\n",
       "      <td>0.835383</td>\n",
       "      <td>0.861434</td>\n",
       "      <td>0.837861</td>\n",
       "      <td>0.854910</td>\n",
       "      <td>0.848451</td>\n",
       "      <td>0.010109</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.543667</td>\n",
       "      <td>0.828303</td>\n",
       "      <td>0.355981</td>\n",
       "      <td>0.032957</td>\n",
       "      <td>5000</td>\n",
       "      <td>8</td>\n",
       "      <td>{'xgbregressor__n_estimators': 5000, 'xgbregre...</td>\n",
       "      <td>0.855428</td>\n",
       "      <td>0.844949</td>\n",
       "      <td>0.854719</td>\n",
       "      <td>0.828442</td>\n",
       "      <td>0.844625</td>\n",
       "      <td>0.845633</td>\n",
       "      <td>0.009752</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.493992</td>\n",
       "      <td>0.475016</td>\n",
       "      <td>0.362459</td>\n",
       "      <td>0.034016</td>\n",
       "      <td>1000</td>\n",
       "      <td>6</td>\n",
       "      <td>{'xgbregressor__n_estimators': 1000, 'xgbregre...</td>\n",
       "      <td>0.865623</td>\n",
       "      <td>0.853529</td>\n",
       "      <td>0.857731</td>\n",
       "      <td>0.828575</td>\n",
       "      <td>0.849153</td>\n",
       "      <td>0.850922</td>\n",
       "      <td>0.012424</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       1.894366      0.018658         0.261792        0.015491   \n",
       "1       3.875738      0.134038         0.297964        0.019988   \n",
       "2       5.164105      0.337951         0.299661        0.010206   \n",
       "3       2.554008      0.213880         0.327158        0.008927   \n",
       "4       1.842755      0.166217         0.325981        0.011370   \n",
       "5       3.731842      0.511455         0.346164        0.032921   \n",
       "6      11.157346      1.348288         0.342296        0.014839   \n",
       "7       8.000274      1.283662         0.367252        0.024799   \n",
       "8       9.543667      0.828303         0.355981        0.032957   \n",
       "9       6.493992      0.475016         0.362459        0.034016   \n",
       "\n",
       "  param_xgbregressor__n_estimators param_xgbregressor__max_depth  \\\n",
       "0                             1000                             2   \n",
       "1                             1000                             4   \n",
       "2                             2000                             8   \n",
       "3                              500                             4   \n",
       "4                              500                             2   \n",
       "5                              500                             6   \n",
       "6                             5000                             6   \n",
       "7                             2000                             4   \n",
       "8                             5000                             8   \n",
       "9                             1000                             6   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'xgbregressor__n_estimators': 1000, 'xgbregre...           0.834215   \n",
       "1  {'xgbregressor__n_estimators': 1000, 'xgbregre...           0.856041   \n",
       "2  {'xgbregressor__n_estimators': 2000, 'xgbregre...           0.855428   \n",
       "3  {'xgbregressor__n_estimators': 500, 'xgbregres...           0.859004   \n",
       "4  {'xgbregressor__n_estimators': 500, 'xgbregres...           0.826916   \n",
       "5  {'xgbregressor__n_estimators': 500, 'xgbregres...           0.866295   \n",
       "6  {'xgbregressor__n_estimators': 5000, 'xgbregre...           0.865567   \n",
       "7  {'xgbregressor__n_estimators': 2000, 'xgbregre...           0.852668   \n",
       "8  {'xgbregressor__n_estimators': 5000, 'xgbregre...           0.855428   \n",
       "9  {'xgbregressor__n_estimators': 1000, 'xgbregre...           0.865623   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.838110           0.833492           0.812999           0.833544   \n",
       "1           0.838577           0.863176           0.837994           0.857625   \n",
       "2           0.844949           0.854719           0.828442           0.844625   \n",
       "3           0.841616           0.863867           0.837594           0.859589   \n",
       "4           0.821482           0.825802           0.804028           0.826654   \n",
       "5           0.854334           0.858057           0.828751           0.849479   \n",
       "6           0.853514           0.857710           0.828576           0.849134   \n",
       "7           0.835383           0.861434           0.837861           0.854910   \n",
       "8           0.844949           0.854719           0.828442           0.844625   \n",
       "9           0.853529           0.857731           0.828575           0.849153   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.830472        0.008902                9  \n",
       "1         0.850683        0.010398                5  \n",
       "2         0.845633        0.009752                7  \n",
       "3         0.852334        0.010605                1  \n",
       "4         0.820976        0.008698               10  \n",
       "5         0.851383        0.012582                2  \n",
       "6         0.850900        0.012408                4  \n",
       "7         0.848451        0.010109                6  \n",
       "8         0.845633        0.009752                7  \n",
       "9         0.850922        0.012424                3  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(search.cv_results_)\n",
    "#scores_df = scores.sort(columns=['rank_test_score']).reset_index(drop='index')\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_jobs=-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merge 2 datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateOfDeparture</th>\n",
       "      <th>Departure</th>\n",
       "      <th>Arrival</th>\n",
       "      <th>WeeksToDeparture</th>\n",
       "      <th>std_wtd_x</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>week</th>\n",
       "      <th>n_days</th>\n",
       "      <th>passsengers_load</th>\n",
       "      <th>distance_km</th>\n",
       "      <th>Max TemperatureC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-06-19</td>\n",
       "      <td>ORD</td>\n",
       "      <td>DFW</td>\n",
       "      <td>12.875000</td>\n",
       "      <td>9.812647</td>\n",
       "      <td>2012</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>15510</td>\n",
       "      <td>32171795.0</td>\n",
       "      <td>1290.179371</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-09-10</td>\n",
       "      <td>LAS</td>\n",
       "      <td>DEN</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>9.466734</td>\n",
       "      <td>2012</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>15593</td>\n",
       "      <td>19959651.0</td>\n",
       "      <td>991.064058</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-05</td>\n",
       "      <td>DEN</td>\n",
       "      <td>LAX</td>\n",
       "      <td>10.863636</td>\n",
       "      <td>9.035883</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>15618</td>\n",
       "      <td>25799841.0</td>\n",
       "      <td>1366.918847</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-10-09</td>\n",
       "      <td>ATL</td>\n",
       "      <td>ORD</td>\n",
       "      <td>11.480000</td>\n",
       "      <td>7.990202</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "      <td>15256</td>\n",
       "      <td>44414121.0</td>\n",
       "      <td>974.522557</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-02-21</td>\n",
       "      <td>DEN</td>\n",
       "      <td>SFO</td>\n",
       "      <td>11.450000</td>\n",
       "      <td>9.517159</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>15391</td>\n",
       "      <td>25799841.0</td>\n",
       "      <td>1538.142783</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DateOfDeparture Departure Arrival  WeeksToDeparture  std_wtd_x  year  month  \\\n",
       "0      2012-06-19       ORD     DFW         12.875000   9.812647  2012      6   \n",
       "1      2012-09-10       LAS     DEN         14.285714   9.466734  2012      9   \n",
       "2      2012-10-05       DEN     LAX         10.863636   9.035883  2012     10   \n",
       "3      2011-10-09       ATL     ORD         11.480000   7.990202  2011     10   \n",
       "4      2012-02-21       DEN     SFO         11.450000   9.517159  2012      2   \n",
       "\n",
       "   day  weekday  week  n_days  passsengers_load  distance_km  Max TemperatureC  \n",
       "0   19        1    25   15510        32171795.0  1290.179371                34  \n",
       "1   10        0    37   15593        19959651.0   991.064058                33  \n",
       "2    5        4    40   15618        25799841.0  1366.918847                22  \n",
       "3    9        6    40   15256        44414121.0   974.522557                27  \n",
       "4   21        1     8   15391        25799841.0  1538.142783                16  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _merge_external_data_2(X):\n",
    "    X = X.copy()  # to avoid raising SettingOnCopyWarning\n",
    "    # Make sure that DateOfDeparture is of dtype datetime\n",
    "    X.loc[:, \"DateOfDeparture\"] = pd.to_datetime(X['DateOfDeparture'])\n",
    "    \n",
    "    #merging dataset 1\n",
    "    data_nicolas = pd.read_csv('testemoica.csv')\n",
    "    data_nicolas = data_nicolas[['Departure', 'Arrival', 'WeeksToDeparture', 'std_wtd', 'year', 'month', 'day', 'weekday', 'week', 'n_days', 'passengers load', 'distance km']]\n",
    "    X_merged = pd.merge(\n",
    "        X, data_nicolas, how='left', left_index=True, right_index=True #on=[['Departure', 'Arrival', 'year', 'month', 'day']], sort=False\n",
    "    )\n",
    "    X_merged = X_merged[['DateOfDeparture', 'Departure_x', 'Arrival_x', 'WeeksToDeparture_x', 'std_wtd_x', 'year', 'month', 'day', 'weekday', 'week', 'n_days', 'passengers load', 'distance km']]\n",
    "    X_merged = X_merged.rename(\n",
    "             columns={'DateOfDeparture':'DateOfDeparture', 'Departure_x':'Departure', 'Arrival_x':'Arrival', 'WeeksToDeparture_x':'WeeksToDeparture', 'std_wtd_x':'std_wtd_x', 'year':'year', 'month':'month', 'day':'day', 'weekday':'weekday', 'week':'week', 'n_days':'n_days', 'passengers load':'enplanement', 'distance km':'distance_km'}\n",
    "              )\n",
    "    \n",
    "    #merging dataset 2\n",
    "    data_temp = pd.read_csv('external_data.csv', parse_dates=[\"Date\"])\n",
    "    data_temp = data_temp[['Date', 'AirPort', 'Max TemperatureC']]\n",
    "    data_temp = data_temp.rename(\n",
    "        columns={'Date': 'DateOfDeparture', 'AirPort': 'Arrival'})\n",
    "    X_merged2 = pd.merge(\n",
    "        X_merged, data_temp, how='left', on=['DateOfDeparture', 'Arrival'], sort=False\n",
    "    )\n",
    "    return X_merged2\n",
    "\n",
    "data_merger_2= FunctionTransformer(_merge_external_data_2)\n",
    "data_merger_2.fit_transform(X).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GradientBoost with 2 datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_GB_2 = {'n_estimators': 1000, #number of decision trees \n",
    "          'subsample': 0.7,\n",
    "          'max_depth': 8,\n",
    "          'min_samples_split': 5,\n",
    "          'learning_rate': 0.01,\n",
    "          'loss': 'ls'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('functiontransformer',\n",
       "                 FunctionTransformer(func=<function _merge_external_data_2 at 0x7ffe66481b80>)),\n",
       "                ('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('functiontransformer',\n",
       "                                                  FunctionTransformer(func=<function _encode_dates at 0x7ffe7be18550>),\n",
       "                                                  ['DateOfDeparture']),\n",
       "                                                 ('ordinalencoder',\n",
       "                                                  OrdinalEncoder(),\n",
       "                                                  ['Arrival', 'Departure'])])),\n",
       "                ('gradientboostingregressor',\n",
       "                 GradientBoostingRegressor(learning_rate=0.01, max_depth=8,\n",
       "                                           min_samples_split=5,\n",
       "                                           n_estimators=1000, subsample=0.7))])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GradBoost_GB_2 = ensemble.GradientBoostingRegressor(**params_GB_2)\n",
    "\n",
    "pipeline7 = make_pipeline(data_merger_2, preprocessor, GradBoost_GB_2)\n",
    "pipeline7.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.3699 +/- 0.0258\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(\n",
    "    pipeline7, X, y, cv=5, scoring='neg_mean_squared_error'\n",
    ")\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "print(\n",
    "    f\"RMSE: {np.mean(rmse_scores):.4f} +/- {np.std(rmse_scores):.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01, score=0.841, total=  17.1s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   17.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01, score=0.818, total=  18.5s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   35.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01, score=0.835, total=  18.4s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   54.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01, score=0.818, total=  18.3s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  1.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01, score=0.838, total=  18.9s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.1, score=0.874, total=  13.4s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  1.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.1, score=0.854, total=  13.3s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  2.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.1, score=0.870, total=  13.8s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.1 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.1, score=0.843, total=  14.1s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.1 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.1, score=0.869, total=  13.3s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.1 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.1, score=0.868, total= 1.4min\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.1 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.1, score=0.848, total= 1.7min\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.1 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.1, score=0.871, total= 1.5min\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.1 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.1, score=0.841, total= 1.3min\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.1 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.1, score=0.863, total= 1.2min\n",
      "[CV] gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.001 \n",
      "[CV]  gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.001, score=0.747, total=  42.2s\n",
      "[CV] gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.001 \n",
      "[CV]  gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.001, score=0.719, total=  40.8s\n",
      "[CV] gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.001 \n",
      "[CV]  gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.001, score=0.745, total=  41.0s\n",
      "[CV] gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.001 \n",
      "[CV]  gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.001, score=0.724, total=  41.3s\n",
      "[CV] gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.001 \n",
      "[CV]  gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.001, score=0.750, total=  41.1s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01, score=0.784, total=   9.5s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01, score=0.756, total=   9.7s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01, score=0.778, total=   9.5s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01, score=0.765, total=   9.5s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01, score=0.784, total=   9.8s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=0.001 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=0.001, score=0.155, total=   5.8s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=0.001 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=0.001, score=0.149, total=   6.0s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=0.001 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=0.001, score=0.157, total=   6.3s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=0.001 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=0.001, score=0.151, total=   6.2s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=0.001 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=0.001, score=0.156, total=   6.3s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=0.1 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=0.1, score=0.834, total=  21.1s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=0.1 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=0.1, score=0.825, total=  20.3s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=0.1 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=0.1, score=0.827, total=  19.8s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=0.1 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=0.1, score=0.815, total=  19.8s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=0.1 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=2000, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=0.1, score=0.836, total=  21.6s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.01, score=0.875, total=  30.8s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.01, score=0.853, total=  29.2s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.01, score=0.870, total=  31.7s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.01, score=0.843, total=  29.4s\n",
      "[CV] gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=0.7, gradientboostingregressor__n_estimators=1000, gradientboostingregressor__max_depth=8, gradientboostingregressor__learning_rate=0.01, score=0.871, total=  30.0s\n",
      "[CV] gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=0.01, score=0.472, total=   4.0s\n",
      "[CV] gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=0.01, score=0.457, total=   4.3s\n",
      "[CV] gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=0.01, score=0.474, total=   4.4s\n",
      "[CV] gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=0.01, score=0.467, total=   4.8s\n",
      "[CV] gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=0.5, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=2, gradientboostingregressor__learning_rate=0.01, score=0.469, total=   4.1s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01, score=0.783, total=  13.3s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01, score=0.758, total=  14.0s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01, score=0.772, total=  13.4s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01, score=0.763, total=  14.1s\n",
      "[CV] gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01 \n",
      "[CV]  gradientboostingregressor__subsample=1.0, gradientboostingregressor__n_estimators=500, gradientboostingregressor__max_depth=5, gradientboostingregressor__learning_rate=0.01, score=0.777, total=  13.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed: 20.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=Pipeline(steps=[('functiontransformer',\n",
       "                                              FunctionTransformer(func=<function _merge_external_data_2 at 0x7ffe66481b80>)),\n",
       "                                             ('columntransformer',\n",
       "                                              ColumnTransformer(remainder='passthrough',\n",
       "                                                                transformers=[('functiontransformer',\n",
       "                                                                               FunctionTransformer(func=<function _encode_dates at 0x7ffe7be18550>),\n",
       "                                                                               ['DateOfDeparture']),\n",
       "                                                                              ('ordinalencoder',\n",
       "                                                                               O...\n",
       "                                              GradientBoostingRegressor(learning_rate=0.01,\n",
       "                                                                        max_depth=8,\n",
       "                                                                        min_samples_split=5,\n",
       "                                                                        n_estimators=2000,\n",
       "                                                                        subsample=0.5))]),\n",
       "                   param_distributions={'gradientboostingregressor__learning_rate': [0.001,\n",
       "                                                                                     0.01,\n",
       "                                                                                     0.1,\n",
       "                                                                                     1.0],\n",
       "                                        'gradientboostingregressor__max_depth': [2,\n",
       "                                                                                 5,\n",
       "                                                                                 8],\n",
       "                                        'gradientboostingregressor__n_estimators': [500,\n",
       "                                                                                    1000,\n",
       "                                                                                    2000],\n",
       "                                        'gradientboostingregressor__subsample': [0.5,\n",
       "                                                                                 0.7,\n",
       "                                                                                 1.0]},\n",
       "                   verbose=8)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = RandomizedSearchCV(pipeline7, param_distributions=space, verbose=8)\n",
    "search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_gradientboostingregressor__subsample</th>\n",
       "      <th>param_gradientboostingregressor__n_estimators</th>\n",
       "      <th>param_gradientboostingregressor__max_depth</th>\n",
       "      <th>param_gradientboostingregressor__learning_rate</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.913896</td>\n",
       "      <td>0.625780</td>\n",
       "      <td>0.309667</td>\n",
       "      <td>0.010040</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'gradientboostingregressor__subsample': 0.7, ...</td>\n",
       "      <td>0.841130</td>\n",
       "      <td>0.817569</td>\n",
       "      <td>0.835098</td>\n",
       "      <td>0.817912</td>\n",
       "      <td>0.837957</td>\n",
       "      <td>0.829933</td>\n",
       "      <td>0.010137</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.289786</td>\n",
       "      <td>0.304292</td>\n",
       "      <td>0.302924</td>\n",
       "      <td>0.036834</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'gradientboostingregressor__subsample': 1.0, ...</td>\n",
       "      <td>0.874333</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.870341</td>\n",
       "      <td>0.842521</td>\n",
       "      <td>0.869075</td>\n",
       "      <td>0.862115</td>\n",
       "      <td>0.011919</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84.854046</td>\n",
       "      <td>10.226326</td>\n",
       "      <td>0.399925</td>\n",
       "      <td>0.059378</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'gradientboostingregressor__subsample': 1.0, ...</td>\n",
       "      <td>0.867839</td>\n",
       "      <td>0.848315</td>\n",
       "      <td>0.871140</td>\n",
       "      <td>0.840818</td>\n",
       "      <td>0.863153</td>\n",
       "      <td>0.858253</td>\n",
       "      <td>0.011702</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.836347</td>\n",
       "      <td>0.474990</td>\n",
       "      <td>0.462150</td>\n",
       "      <td>0.019253</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'gradientboostingregressor__subsample': 0.5, ...</td>\n",
       "      <td>0.746784</td>\n",
       "      <td>0.718503</td>\n",
       "      <td>0.744882</td>\n",
       "      <td>0.724376</td>\n",
       "      <td>0.750279</td>\n",
       "      <td>0.736965</td>\n",
       "      <td>0.012928</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.321905</td>\n",
       "      <td>0.137984</td>\n",
       "      <td>0.266680</td>\n",
       "      <td>0.005739</td>\n",
       "      <td>0.7</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'gradientboostingregressor__subsample': 0.7, ...</td>\n",
       "      <td>0.784133</td>\n",
       "      <td>0.756271</td>\n",
       "      <td>0.778317</td>\n",
       "      <td>0.764948</td>\n",
       "      <td>0.783981</td>\n",
       "      <td>0.773530</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.844905</td>\n",
       "      <td>0.189687</td>\n",
       "      <td>0.270630</td>\n",
       "      <td>0.020624</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'gradientboostingregressor__subsample': 1.0, ...</td>\n",
       "      <td>0.154930</td>\n",
       "      <td>0.149048</td>\n",
       "      <td>0.156867</td>\n",
       "      <td>0.150811</td>\n",
       "      <td>0.156012</td>\n",
       "      <td>0.153534</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20.202624</td>\n",
       "      <td>0.677988</td>\n",
       "      <td>0.321341</td>\n",
       "      <td>0.066372</td>\n",
       "      <td>1</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'gradientboostingregressor__subsample': 1.0, ...</td>\n",
       "      <td>0.834318</td>\n",
       "      <td>0.825241</td>\n",
       "      <td>0.826871</td>\n",
       "      <td>0.814659</td>\n",
       "      <td>0.836355</td>\n",
       "      <td>0.827489</td>\n",
       "      <td>0.007685</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29.848711</td>\n",
       "      <td>0.920852</td>\n",
       "      <td>0.363366</td>\n",
       "      <td>0.037182</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'gradientboostingregressor__subsample': 0.7, ...</td>\n",
       "      <td>0.875295</td>\n",
       "      <td>0.852529</td>\n",
       "      <td>0.869910</td>\n",
       "      <td>0.842837</td>\n",
       "      <td>0.870620</td>\n",
       "      <td>0.862238</td>\n",
       "      <td>0.012412</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.029249</td>\n",
       "      <td>0.258289</td>\n",
       "      <td>0.271449</td>\n",
       "      <td>0.030301</td>\n",
       "      <td>0.5</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'gradientboostingregressor__subsample': 0.5, ...</td>\n",
       "      <td>0.471588</td>\n",
       "      <td>0.456919</td>\n",
       "      <td>0.474424</td>\n",
       "      <td>0.467243</td>\n",
       "      <td>0.468933</td>\n",
       "      <td>0.467821</td>\n",
       "      <td>0.005970</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13.318954</td>\n",
       "      <td>0.386995</td>\n",
       "      <td>0.275624</td>\n",
       "      <td>0.011840</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'gradientboostingregressor__subsample': 1.0, ...</td>\n",
       "      <td>0.782952</td>\n",
       "      <td>0.758361</td>\n",
       "      <td>0.772332</td>\n",
       "      <td>0.763302</td>\n",
       "      <td>0.776974</td>\n",
       "      <td>0.770784</td>\n",
       "      <td>0.008934</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      17.913896      0.625780         0.309667        0.010040   \n",
       "1      13.289786      0.304292         0.302924        0.036834   \n",
       "2      84.854046     10.226326         0.399925        0.059378   \n",
       "3      40.836347      0.474990         0.462150        0.019253   \n",
       "4       9.321905      0.137984         0.266680        0.005739   \n",
       "5       5.844905      0.189687         0.270630        0.020624   \n",
       "6      20.202624      0.677988         0.321341        0.066372   \n",
       "7      29.848711      0.920852         0.363366        0.037182   \n",
       "8       4.029249      0.258289         0.271449        0.030301   \n",
       "9      13.318954      0.386995         0.275624        0.011840   \n",
       "\n",
       "  param_gradientboostingregressor__subsample  \\\n",
       "0                                        0.7   \n",
       "1                                          1   \n",
       "2                                          1   \n",
       "3                                        0.5   \n",
       "4                                        0.7   \n",
       "5                                          1   \n",
       "6                                          1   \n",
       "7                                        0.7   \n",
       "8                                        0.5   \n",
       "9                                          1   \n",
       "\n",
       "  param_gradientboostingregressor__n_estimators  \\\n",
       "0                                          1000   \n",
       "1                                           500   \n",
       "2                                          2000   \n",
       "3                                          2000   \n",
       "4                                           500   \n",
       "5                                           500   \n",
       "6                                          2000   \n",
       "7                                          1000   \n",
       "8                                           500   \n",
       "9                                           500   \n",
       "\n",
       "  param_gradientboostingregressor__max_depth  \\\n",
       "0                                          5   \n",
       "1                                          5   \n",
       "2                                          8   \n",
       "3                                          8   \n",
       "4                                          5   \n",
       "5                                          2   \n",
       "6                                          2   \n",
       "7                                          8   \n",
       "8                                          2   \n",
       "9                                          5   \n",
       "\n",
       "  param_gradientboostingregressor__learning_rate  \\\n",
       "0                                           0.01   \n",
       "1                                            0.1   \n",
       "2                                            0.1   \n",
       "3                                          0.001   \n",
       "4                                           0.01   \n",
       "5                                          0.001   \n",
       "6                                            0.1   \n",
       "7                                           0.01   \n",
       "8                                           0.01   \n",
       "9                                           0.01   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'gradientboostingregressor__subsample': 0.7, ...           0.841130   \n",
       "1  {'gradientboostingregressor__subsample': 1.0, ...           0.874333   \n",
       "2  {'gradientboostingregressor__subsample': 1.0, ...           0.867839   \n",
       "3  {'gradientboostingregressor__subsample': 0.5, ...           0.746784   \n",
       "4  {'gradientboostingregressor__subsample': 0.7, ...           0.784133   \n",
       "5  {'gradientboostingregressor__subsample': 1.0, ...           0.154930   \n",
       "6  {'gradientboostingregressor__subsample': 1.0, ...           0.834318   \n",
       "7  {'gradientboostingregressor__subsample': 0.7, ...           0.875295   \n",
       "8  {'gradientboostingregressor__subsample': 0.5, ...           0.471588   \n",
       "9  {'gradientboostingregressor__subsample': 1.0, ...           0.782952   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.817569           0.835098           0.817912           0.837957   \n",
       "1           0.854305           0.870341           0.842521           0.869075   \n",
       "2           0.848315           0.871140           0.840818           0.863153   \n",
       "3           0.718503           0.744882           0.724376           0.750279   \n",
       "4           0.756271           0.778317           0.764948           0.783981   \n",
       "5           0.149048           0.156867           0.150811           0.156012   \n",
       "6           0.825241           0.826871           0.814659           0.836355   \n",
       "7           0.852529           0.869910           0.842837           0.870620   \n",
       "8           0.456919           0.474424           0.467243           0.468933   \n",
       "9           0.758361           0.772332           0.763302           0.776974   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.829933        0.010137                4  \n",
       "1         0.862115        0.011919                2  \n",
       "2         0.858253        0.011702                3  \n",
       "3         0.736965        0.012928                8  \n",
       "4         0.773530        0.011100                6  \n",
       "5         0.153534        0.003057               10  \n",
       "6         0.827489        0.007685                5  \n",
       "7         0.862238        0.012412                1  \n",
       "8         0.467821        0.005970                9  \n",
       "9         0.770784        0.008934                7  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(search.cv_results_)\n",
    "#scores_df = scores.sort(columns=['rank_test_score']).reset_index(drop='index')\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merge enplanment, distance, GDP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateOfDeparture</th>\n",
       "      <th>Departure</th>\n",
       "      <th>Arrival</th>\n",
       "      <th>WeeksToDeparture</th>\n",
       "      <th>std_wtd_x</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>week</th>\n",
       "      <th>n_days</th>\n",
       "      <th>enplanement</th>\n",
       "      <th>distance_km</th>\n",
       "      <th>LineCode</th>\n",
       "      <th>gdp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-06-19</td>\n",
       "      <td>ORD</td>\n",
       "      <td>DFW</td>\n",
       "      <td>12.875</td>\n",
       "      <td>9.812647</td>\n",
       "      <td>2012</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>15510</td>\n",
       "      <td>32171795.0</td>\n",
       "      <td>1290.179371</td>\n",
       "      <td>1.0</td>\n",
       "      <td>561588192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-06-19</td>\n",
       "      <td>ORD</td>\n",
       "      <td>DFW</td>\n",
       "      <td>12.875</td>\n",
       "      <td>9.812647</td>\n",
       "      <td>2012</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>15510</td>\n",
       "      <td>32171795.0</td>\n",
       "      <td>1290.179371</td>\n",
       "      <td>2.0</td>\n",
       "      <td>508763428.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-06-19</td>\n",
       "      <td>ORD</td>\n",
       "      <td>DFW</td>\n",
       "      <td>12.875</td>\n",
       "      <td>9.812647</td>\n",
       "      <td>2012</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>15510</td>\n",
       "      <td>32171795.0</td>\n",
       "      <td>1290.179371</td>\n",
       "      <td>3.0</td>\n",
       "      <td>550397.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-06-19</td>\n",
       "      <td>ORD</td>\n",
       "      <td>DFW</td>\n",
       "      <td>12.875</td>\n",
       "      <td>9.812647</td>\n",
       "      <td>2012</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>15510</td>\n",
       "      <td>32171795.0</td>\n",
       "      <td>1290.179371</td>\n",
       "      <td>6.0</td>\n",
       "      <td>272006.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-06-19</td>\n",
       "      <td>ORD</td>\n",
       "      <td>DFW</td>\n",
       "      <td>12.875</td>\n",
       "      <td>9.812647</td>\n",
       "      <td>2012</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>15510</td>\n",
       "      <td>32171795.0</td>\n",
       "      <td>1290.179371</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DateOfDeparture Departure Arrival  WeeksToDeparture  std_wtd_x  year  month  \\\n",
       "0      2012-06-19       ORD     DFW            12.875   9.812647  2012      6   \n",
       "1      2012-06-19       ORD     DFW            12.875   9.812647  2012      6   \n",
       "2      2012-06-19       ORD     DFW            12.875   9.812647  2012      6   \n",
       "3      2012-06-19       ORD     DFW            12.875   9.812647  2012      6   \n",
       "4      2012-06-19       ORD     DFW            12.875   9.812647  2012      6   \n",
       "\n",
       "   day  weekday  week  n_days  enplanement  distance_km  LineCode          gdp  \n",
       "0   19        1    25   15510   32171795.0  1290.179371       1.0  561588192.0  \n",
       "1   19        1    25   15510   32171795.0  1290.179371       2.0  508763428.0  \n",
       "2   19        1    25   15510   32171795.0  1290.179371       3.0     550397.0  \n",
       "3   19        1    25   15510   32171795.0  1290.179371       6.0     272006.0  \n",
       "4   19        1    25   15510   32171795.0  1290.179371      10.0          NaN  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _merge_external_data_3(X):\n",
    "    X = X.copy()  # to avoid raising SettingOnCopyWarning\n",
    "    # Make sure that DateOfDeparture is of dtype datetime\n",
    "    X.loc[:, \"DateOfDeparture\"] = pd.to_datetime(X['DateOfDeparture'])\n",
    "    \n",
    "    #merging dataset 1\n",
    "    data_nicolas = pd.read_csv('testemoica.csv')\n",
    "    data_nicolas = data_nicolas[['Departure', 'Arrival', 'WeeksToDeparture', 'std_wtd', 'year', 'month', 'day', 'weekday', 'week', 'n_days', 'passengers load', 'distance km']]\n",
    "    X_merged = pd.merge(\n",
    "        X, data_nicolas, how='left', left_index=True, right_index=True #on=[['Departure', 'Arrival', 'year', 'month', 'day']], sort=False\n",
    "    )\n",
    "    X_merged = X_merged[['DateOfDeparture', 'Departure_x', 'Arrival_x', 'WeeksToDeparture_x', 'std_wtd_x', 'year', 'month', 'day', 'weekday', 'week', 'n_days', 'passengers load', 'distance km']]\n",
    "    X_merged = X_merged.rename(\n",
    "             columns={'DateOfDeparture':'DateOfDeparture', 'Departure_x':'Departure', 'Arrival_x':'Arrival', 'WeeksToDeparture_x':'WeeksToDeparture', 'std_wtd_x':'std_wtd_x', 'year':'year', 'month':'month', 'day':'day', 'weekday':'weekday', 'week':'week', 'n_days':'n_days', 'passengers load':'enplanement', 'distance km':'distance_km'}\n",
    "              )\n",
    "    \n",
    "    #merging dataset 2\n",
    "    data_gdp = pd.read_csv('gdp_data_processed.csv', parse_dates=[\"year\"])\n",
    "    data_gdp = data_gdp.rename(\n",
    "               columns={'year' : 'DateOfDeparture', 'airport' : 'Departure', 'gdp' : 'gdp', 'LineCode' : 'LineCode'})\n",
    "    data_gdp = date_encoder.fit_transform(data_gdp)\n",
    "    data_gdp = data_gdp[['Departure', 'LineCode', 'gdp', 'year']]\n",
    "    \n",
    "    X_merged2 = pd.merge(\n",
    "        X_merged, data_gdp, how='left', on=['year', 'Departure'], sort=False\n",
    "    )\n",
    "    return X_merged2\n",
    "\n",
    "data_merger_3= FunctionTransformer(_merge_external_data_3)\n",
    "data_merger_3.fit_transform(X).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LineCode</th>\n",
       "      <th>Departure</th>\n",
       "      <th>gdp</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>week</th>\n",
       "      <th>n_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>277405509.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>14975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>250779823.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>14975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>14975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>267771.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>14975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>3704264.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>14975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>88.0</td>\n",
       "      <td>SEA</td>\n",
       "      <td>36704724.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2096</th>\n",
       "      <td>89.0</td>\n",
       "      <td>SEA</td>\n",
       "      <td>8691437.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2097</th>\n",
       "      <td>90.0</td>\n",
       "      <td>SEA</td>\n",
       "      <td>87187960.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098</th>\n",
       "      <td>91.0</td>\n",
       "      <td>SEA</td>\n",
       "      <td>56342381.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>92.0</td>\n",
       "      <td>SEA</td>\n",
       "      <td>196521380.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LineCode Departure          gdp  year  month  day  weekday  week  n_days\n",
       "0          1.0       ATL  277405509.0  2011      1    1        5    52   14975\n",
       "1          2.0       ATL  250779823.0  2011      1    1        5    52   14975\n",
       "2          3.0       ATL          NaN  2011      1    1        5    52   14975\n",
       "3          6.0       ATL     267771.0  2011      1    1        5    52   14975\n",
       "4         10.0       ATL    3704264.0  2011      1    1        5    52   14975\n",
       "...        ...       ...          ...   ...    ...  ...      ...   ...     ...\n",
       "2095      88.0       SEA   36704724.0  2013      1    1        1     1   15706\n",
       "2096      89.0       SEA    8691437.0  2013      1    1        1     1   15706\n",
       "2097      90.0       SEA   87187960.0  2013      1    1        1     1   15706\n",
       "2098      91.0       SEA   56342381.0  2013      1    1        1     1   15706\n",
       "2099      92.0       SEA  196521380.0  2013      1    1        1     1   15706\n",
       "\n",
       "[2100 rows x 9 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_gdp = pd.read_csv('gdp_data_processed.csv', parse_dates=[\"year\"])\n",
    "data_gdp = data_gdp.rename(\n",
    "        columns={'year' : 'DateOfDeparture', 'airport' : 'Departure', 'gdp' : 'gdp'})\n",
    "data_gdp = date_encoder.fit_transform(data_gdp)\n",
    "data_gdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
